{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House sales prices in King County\n",
    "\n",
    "A project on exploratory data analysis.\n",
    "\n",
    "Sebastian Thomas @ neue fische Bootcamp Data Science<br />\n",
    "(datascience at sebastianthomas dot de)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Predictive analysis\n",
    "\n",
    "We fit some predictive models on our preprocessed data.\n",
    "\n",
    "## Imports\n",
    "\n",
    "### Modules, classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import of modules\n",
    "from importlib import import_module\n",
    "\n",
    "# object persistence\n",
    "import joblib\n",
    "\n",
    "# data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# machine learning\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler, Normalizer, OneHotEncoder, OrdinalEncoder, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, VotingRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, make_scorer\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# custom modules\n",
    "from modules.ds import root_mean_squared_error, median_absolute_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers\n",
    "\n",
    "Some helping functions to evaluate our regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_evaluation(regressor, X_train, X_test, y_train, y_test):\n",
    "    print('R^2:   {:.3f}, {:.3f}'.format(r2_score(y_train, regressor.predict(X_train)),\n",
    "                                         r2_score(y_test, regressor.predict(X_test))))\n",
    "    print('RMSE:  {:.0f}, {:.0f}'.format(root_mean_squared_error(y_train, regressor.predict(X_train)),\n",
    "                                         root_mean_squared_error(y_test, regressor.predict(X_test))))\n",
    "    print('MAE:   {:.0f}, {:.0f}'.format(mean_absolute_error(y_train, regressor.predict(X_train)),\n",
    "                                         mean_absolute_error(y_test, regressor.predict(X_test))))\n",
    "    print('MedAE: {:.0f}, {:.0f}'.format(median_absolute_error(y_train, regressor.predict(X_train)),\n",
    "                                         median_absolute_error(y_test, regressor.predict(X_test))))\n",
    "    print('MAPE:  {:.3f}, {:.3f}'.format(mean_absolute_percentage_error(y_train, regressor.predict(X_train)),\n",
    "                                         mean_absolute_percentage_error(y_test, regressor.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "We import the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_living log</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_above log</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>has_basement</th>\n",
       "      <th>room_size</th>\n",
       "      <th>...</th>\n",
       "      <th>long</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>zipcode cat</th>\n",
       "      <th>condition</th>\n",
       "      <th>condition bin</th>\n",
       "      <th>grade</th>\n",
       "      <th>grade bin</th>\n",
       "      <th>view</th>\n",
       "      <th>view bin</th>\n",
       "      <th>waterfront</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8724300010</th>\n",
       "      <td>548000.0</td>\n",
       "      <td>2014-09-09</td>\n",
       "      <td>2014-09</td>\n",
       "      <td>3420.0</td>\n",
       "      <td>8.137688</td>\n",
       "      <td>2330.0</td>\n",
       "      <td>7.754053</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>True</td>\n",
       "      <td>414.545455</td>\n",
       "      <td>...</td>\n",
       "      <td>-121.982</td>\n",
       "      <td>98019</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423400005</th>\n",
       "      <td>249950.0</td>\n",
       "      <td>2014-08-15</td>\n",
       "      <td>2014-08</td>\n",
       "      <td>1370.0</td>\n",
       "      <td>7.223296</td>\n",
       "      <td>1370.0</td>\n",
       "      <td>7.223296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>274.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-122.182</td>\n",
       "      <td>98058</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>6</td>\n",
       "      <td>3 to 6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7202330280</th>\n",
       "      <td>401000.0</td>\n",
       "      <td>2014-09-22</td>\n",
       "      <td>2014-09</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>7.208600</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>7.208600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-122.036</td>\n",
       "      <td>98053</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828000230</th>\n",
       "      <td>498000.0</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>2014-07</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>7.390799</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>7.074117</td>\n",
       "      <td>440.0</td>\n",
       "      <td>True</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-122.128</td>\n",
       "      <td>98052</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3342100995</th>\n",
       "      <td>449000.0</td>\n",
       "      <td>2014-10-22</td>\n",
       "      <td>2014-10</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>7.591357</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>7.591357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-122.207</td>\n",
       "      <td>98056</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               price       date    month  sqft_living  sqft_living log  \\\n",
       "id                                                                       \n",
       "8724300010  548000.0 2014-09-09  2014-09       3420.0         8.137688   \n",
       "1423400005  249950.0 2014-08-15  2014-08       1370.0         7.223296   \n",
       "7202330280  401000.0 2014-09-22  2014-09       1350.0         7.208600   \n",
       "1828000230  498000.0 2014-07-14  2014-07       1620.0         7.390799   \n",
       "3342100995  449000.0 2014-10-22  2014-10       1980.0         7.591357   \n",
       "\n",
       "            sqft_above  sqft_above log  sqft_basement  has_basement  \\\n",
       "id                                                                    \n",
       "8724300010      2330.0        7.754053         1090.0          True   \n",
       "1423400005      1370.0        7.223296            0.0         False   \n",
       "7202330280      1350.0        7.208600            0.0         False   \n",
       "1828000230      1180.0        7.074117          440.0          True   \n",
       "3342100995      1980.0        7.591357            0.0         False   \n",
       "\n",
       "             room_size  ...     long  zipcode  zipcode cat  condition  \\\n",
       "id                      ...                                             \n",
       "8724300010  414.545455  ... -121.982    98019            2          3   \n",
       "1423400005  274.000000  ... -122.182    98058            1          4   \n",
       "7202330280  216.000000  ... -122.036    98053            4          3   \n",
       "1828000230  270.000000  ... -122.128    98052            4          3   \n",
       "3342100995  264.000000  ... -122.207    98056            1          3   \n",
       "\n",
       "            condition bin  grade  grade bin  view view bin  waterfront  \n",
       "id                                                                      \n",
       "8724300010         3 to 4     10         10     0        0       False  \n",
       "1423400005         3 to 4      6     3 to 6     0        0       False  \n",
       "7202330280         3 to 4      7          7     0        0       False  \n",
       "1828000230         3 to 4      7          7     0        0       False  \n",
       "3342100995         3 to 4      8          8     0        0       False  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houses_train = pd.read_pickle('data/king_county_train_2_engineered.pickle')\n",
    "houses_train.sample(5, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = houses_train['price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_fit, houses_valid, y_fit, y_valid = train_test_split(houses_train, y_train, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['price', 'date', 'month', 'sqft_living', 'sqft_living log',\n",
       "       'sqft_above', 'sqft_above log', 'sqft_basement', 'has_basement',\n",
       "       'room_size', 'room_size log', 'base_area', 'base_area log', 'sqft_lot',\n",
       "       'sqft_living15', 'sqft_living15 log', 'sqft_lot15', 'bedrooms',\n",
       "       'bedrooms bin', 'bathrooms', 'bathrooms bin', 'bathrooms_ratio',\n",
       "       'bathrooms_ratio bin', 'floors', 'floors bin', 'yr_built',\n",
       "       'decade_built', 'yr_built bin', 'yr_renovated', 'is_renovated', 'lat',\n",
       "       'long', 'zipcode', 'zipcode cat', 'condition', 'condition bin', 'grade',\n",
       "       'grade bin', 'view', 'view bin', 'waterfront'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houses_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['sqft_living log', 'base_area log', 'sqft_lot', 'lat', 'long']\n",
    "categorical_features = ['bedrooms bin', 'bathrooms bin', 'bathrooms_ratio bin', 'floors bin', 'yr_built bin', \n",
    "                        'zipcode cat', 'condition bin', 'grade bin', 'view bin']\n",
    "boolean_features = ['has_basement', 'is_renovated', 'waterfront']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rough analysis\n",
    "\n",
    "We start with a rough analysis.\n",
    "\n",
    "### Dummy approach\n",
    "\n",
    "As a baseline approach, we predict by the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fit = np.empty((y_fit.size, 1))\n",
    "X_valid = np.empty((y_valid.size, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2:   -0.062, -0.065\n",
      "RMSE:  376836, 393670\n",
      "MAE:   222420, 222612\n",
      "MedAE: 150000, 148000\n",
      "MAPE:  0.423, 0.409\n"
     ]
    }
   ],
   "source": [
    "dummy_regressor = DummyRegressor(strategy='median')\n",
    "dummy_regressor.fit(X_fit, y_fit);\n",
    "print_evaluation(dummy_regressor, X_fit, X_valid, y_fit, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic approach with `'sqft_living log'`\n",
    "\n",
    "Next, we do some basic linear approaches. We start with just the feature `'sqft_living log'` (logarithm of living space area)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fit = houses_fit[['sqft_living log']]\n",
    "X_valid = houses_valid[['sqft_living log']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2:   0.375, 0.372\n",
      "RMSE:  289150, 302283\n",
      "MAE:   188190, 184524\n",
      "MedAE: 144977, 136775\n",
      "MAPE:  0.405, 0.386\n"
     ]
    }
   ],
   "source": [
    "# with sklearn\n",
    "linear_regressor = LinearRegression()\n",
    "linear_regressor.fit(X_fit, y_fit);\n",
    "print_evaluation(linear_regressor, X_fit, X_valid, y_fit, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.375</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.375</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   8665.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 27 Jun 2020</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:37:01</td>     <th>  Log-Likelihood:    </th> <td>-2.0232e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 14458</td>      <th>  AIC:               </th>  <td>4.046e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 14456</td>      <th>  BIC:               </th>  <td>4.047e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>           <td>-3.449e+06</td> <td> 4.29e+04</td> <td>  -80.339</td> <td> 0.000</td> <td>-3.53e+06</td> <td>-3.36e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_living log</th> <td> 5.281e+05</td> <td> 5673.530</td> <td>   93.088</td> <td> 0.000</td> <td> 5.17e+05</td> <td> 5.39e+05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>12921.107</td> <th>  Durbin-Watson:     </th>  <td>   1.987</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>1139262.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.928</td>   <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>45.772</td>   <th>  Cond. No.          </th>  <td>    137.</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.375\n",
       "Model:                            OLS   Adj. R-squared:                  0.375\n",
       "Method:                 Least Squares   F-statistic:                     8665.\n",
       "Date:                Sat, 27 Jun 2020   Prob (F-statistic):               0.00\n",
       "Time:                        15:37:01   Log-Likelihood:            -2.0232e+05\n",
       "No. Observations:               14458   AIC:                         4.046e+05\n",
       "Df Residuals:                   14456   BIC:                         4.047e+05\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================\n",
       "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "const           -3.449e+06   4.29e+04    -80.339      0.000   -3.53e+06   -3.36e+06\n",
       "sqft_living log  5.281e+05   5673.530     93.088      0.000    5.17e+05    5.39e+05\n",
       "==============================================================================\n",
       "Omnibus:                    12921.107   Durbin-Watson:                   1.987\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1139262.900\n",
       "Skew:                           3.928   Prob(JB):                         0.00\n",
       "Kurtosis:                      45.772   Cond. No.                         137.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with statsmodels\n",
    "linear_regressor = OLS(y_fit, add_constant(X_fit))\n",
    "results = linear_regressor.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic approach with `'sqft_living log'`, `'sqft_lot'`, `'lat'`, `'long'`\n",
    "\n",
    "We add the features `'sqft_lot'` (lot space), `'lat'` (lattitude) and `'long'` (longitude)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fit = houses_fit[['sqft_living log', 'sqft_lot', 'lat', 'long']]\n",
    "X_valid = houses_valid[['sqft_living log', 'sqft_lot', 'lat', 'long']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2:   0.469, 0.453\n",
      "RMSE:  266578, 282121\n",
      "MAE:   164509, 163007\n",
      "MedAE: 118236, 117162\n",
      "MAPE:  0.342, 0.331\n"
     ]
    }
   ],
   "source": [
    "linear_regressor = LinearRegression()\n",
    "linear_regressor.fit(X_fit, y_fit);\n",
    "print_evaluation(linear_regressor, X_fit, X_valid, y_fit, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.469</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.468</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   3186.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 27 Jun 2020</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:37:01</td>     <th>  Log-Likelihood:    </th> <td>-2.0114e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 14458</td>      <th>  AIC:               </th>  <td>4.023e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 14453</td>      <th>  BIC:               </th>  <td>4.023e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>           <td>-7.431e+07</td> <td> 2.11e+06</td> <td>  -35.138</td> <td> 0.000</td> <td>-7.85e+07</td> <td>-7.02e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_living log</th> <td> 5.381e+05</td> <td> 5445.604</td> <td>   98.813</td> <td> 0.000</td> <td> 5.27e+05</td> <td> 5.49e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_lot</th>        <td>    0.4251</td> <td>    0.053</td> <td>    8.062</td> <td> 0.000</td> <td>    0.322</td> <td>    0.528</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lat</th>             <td> 7.216e+05</td> <td> 1.62e+04</td> <td>   44.595</td> <td> 0.000</td> <td>  6.9e+05</td> <td> 7.53e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>long</th>            <td>-2.983e+05</td> <td> 1.69e+04</td> <td>  -17.668</td> <td> 0.000</td> <td>-3.31e+05</td> <td>-2.65e+05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14371.403</td> <th>  Durbin-Watson:     </th>  <td>   2.004</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>1858373.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 4.570</td>   <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>57.784</td>   <th>  Cond. No.          </th>  <td>4.40e+07</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 4.4e+07. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.469\n",
       "Model:                            OLS   Adj. R-squared:                  0.468\n",
       "Method:                 Least Squares   F-statistic:                     3186.\n",
       "Date:                Sat, 27 Jun 2020   Prob (F-statistic):               0.00\n",
       "Time:                        15:37:01   Log-Likelihood:            -2.0114e+05\n",
       "No. Observations:               14458   AIC:                         4.023e+05\n",
       "Df Residuals:                   14453   BIC:                         4.023e+05\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================\n",
       "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "const           -7.431e+07   2.11e+06    -35.138      0.000   -7.85e+07   -7.02e+07\n",
       "sqft_living log  5.381e+05   5445.604     98.813      0.000    5.27e+05    5.49e+05\n",
       "sqft_lot            0.4251      0.053      8.062      0.000       0.322       0.528\n",
       "lat              7.216e+05   1.62e+04     44.595      0.000     6.9e+05    7.53e+05\n",
       "long            -2.983e+05   1.69e+04    -17.668      0.000   -3.31e+05   -2.65e+05\n",
       "==============================================================================\n",
       "Omnibus:                    14371.403   Durbin-Watson:                   2.004\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1858373.110\n",
       "Skew:                           4.570   Prob(JB):                         0.00\n",
       "Kurtosis:                      57.784   Cond. No.                     4.40e+07\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 4.4e+07. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regressor = OLS(y_fit, add_constant(X_fit))\n",
    "results = linear_regressor.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinary approach with `LinearRegression`\n",
    "\n",
    "In the next approaches, we will work with more features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_transformer = ColumnTransformer([\n",
    "    ('numericals_transformer', StandardScaler(), numerical_features),\n",
    "    ('categoricals_transformer', OneHotEncoder(drop='first'), categorical_features),\n",
    "    ('booleans_transformer', 'passthrough', boolean_features)\n",
    "], n_jobs=-1)\n",
    "\n",
    "X_fit = column_transformer.fit_transform(houses_fit)\n",
    "X_valid = column_transformer.transform(houses_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2:   0.831, 0.768\n",
      "RMSE:  150453, 183818\n",
      "MAE:   91411, 94884\n",
      "MedAE: 60080, 57900\n",
      "MAPE:  0.177, 0.175\n"
     ]
    }
   ],
   "source": [
    "linear_regressor = LinearRegression()\n",
    "linear_regressor.fit(X_fit, y_fit)\n",
    "print_evaluation(linear_regressor, X_fit, X_valid, y_fit, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.831</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.830</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   1334.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 27 Jun 2020</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:37:02</td>     <th>  Log-Likelihood:    </th> <td>-1.9287e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 14458</td>      <th>  AIC:               </th>  <td>3.859e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 14404</td>      <th>  BIC:               </th>  <td>3.863e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    53</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 6.323e+05</td> <td> 7.89e+04</td> <td>    8.018</td> <td> 0.000</td> <td> 4.78e+05</td> <td> 7.87e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> 7.405e+04</td> <td> 9091.486</td> <td>    8.145</td> <td> 0.000</td> <td> 5.62e+04</td> <td> 9.19e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td> 1.951e+04</td> <td> 8826.793</td> <td>    2.210</td> <td> 0.027</td> <td> 2208.616</td> <td> 3.68e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> 8225.2209</td> <td> 1334.120</td> <td>    6.165</td> <td> 0.000</td> <td> 5610.173</td> <td> 1.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td> 2.539e+04</td> <td> 2130.881</td> <td>   11.913</td> <td> 0.000</td> <td> 2.12e+04</td> <td> 2.96e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>-2.387e+04</td> <td> 1703.360</td> <td>  -14.013</td> <td> 0.000</td> <td>-2.72e+04</td> <td>-2.05e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>-1.219e+04</td> <td> 1.63e+04</td> <td>   -0.748</td> <td> 0.454</td> <td>-4.41e+04</td> <td> 1.97e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>-1.035e+04</td> <td>  1.9e+04</td> <td>   -0.546</td> <td> 0.585</td> <td>-4.76e+04</td> <td> 2.68e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>-2.264e+04</td> <td> 2.04e+04</td> <td>   -1.110</td> <td> 0.267</td> <td>-6.26e+04</td> <td> 1.74e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>-3.044e+04</td> <td> 2.24e+04</td> <td>   -1.361</td> <td> 0.173</td> <td>-7.43e+04</td> <td> 1.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>-7.667e+04</td> <td> 2.57e+04</td> <td>   -2.988</td> <td> 0.003</td> <td>-1.27e+05</td> <td>-2.64e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td> 1.924e+04</td> <td> 7.57e+04</td> <td>    0.254</td> <td> 0.799</td> <td>-1.29e+05</td> <td> 1.68e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td> -868.2025</td> <td> 7.66e+04</td> <td>   -0.011</td> <td> 0.991</td> <td>-1.51e+05</td> <td> 1.49e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td> 1.941e+04</td> <td> 7.72e+04</td> <td>    0.252</td> <td> 0.801</td> <td>-1.32e+05</td> <td> 1.71e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td> 9.842e+04</td> <td> 7.79e+04</td> <td>    1.264</td> <td> 0.206</td> <td>-5.42e+04</td> <td> 2.51e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td> 1.953e+05</td> <td> 7.85e+04</td> <td>    2.489</td> <td> 0.013</td> <td> 4.15e+04</td> <td> 3.49e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td> 5.558e+05</td> <td> 8.15e+04</td> <td>    6.820</td> <td> 0.000</td> <td> 3.96e+05</td> <td> 7.16e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td> 2.516e+06</td> <td> 1.24e+05</td> <td>   20.293</td> <td> 0.000</td> <td> 2.27e+06</td> <td> 2.76e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td> 1.371e+04</td> <td> 8907.656</td> <td>    1.539</td> <td> 0.124</td> <td>-3748.091</td> <td> 3.12e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td> 1.562e+04</td> <td> 1.13e+04</td> <td>    1.386</td> <td> 0.166</td> <td>-6472.610</td> <td> 3.77e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td> 7612.1944</td> <td> 1.32e+04</td> <td>    0.578</td> <td> 0.563</td> <td>-1.82e+04</td> <td> 3.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td> 3322.1294</td> <td> 1.88e+04</td> <td>    0.177</td> <td> 0.860</td> <td>-3.35e+04</td> <td> 4.02e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>-5.011e+04</td> <td> 5.21e+04</td> <td>   -0.961</td> <td> 0.337</td> <td>-1.52e+05</td> <td> 5.21e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td> 2.456e+04</td> <td> 1.25e+04</td> <td>    1.968</td> <td> 0.049</td> <td>  102.411</td> <td>  4.9e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td> 1.275e+05</td> <td> 2.36e+04</td> <td>    5.401</td> <td> 0.000</td> <td> 8.12e+04</td> <td> 1.74e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>  1.17e+04</td> <td> 2.24e+04</td> <td>    0.522</td> <td> 0.601</td> <td>-3.22e+04</td> <td> 5.56e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>-6.538e+04</td> <td> 4711.110</td> <td>  -13.877</td> <td> 0.000</td> <td>-7.46e+04</td> <td>-5.61e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>-9.697e+04</td> <td> 5644.136</td> <td>  -17.180</td> <td> 0.000</td> <td>-1.08e+05</td> <td>-8.59e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>-1.227e+05</td> <td> 7836.165</td> <td>  -15.655</td> <td> 0.000</td> <td>-1.38e+05</td> <td>-1.07e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>-1.148e+05</td> <td> 8468.126</td> <td>  -13.551</td> <td> 0.000</td> <td>-1.31e+05</td> <td>-9.82e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>-6.829e+04</td> <td> 1.03e+04</td> <td>   -6.650</td> <td> 0.000</td> <td>-8.84e+04</td> <td>-4.82e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td> 5.401e+04</td> <td> 4614.921</td> <td>   11.704</td> <td> 0.000</td> <td>  4.5e+04</td> <td> 6.31e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td> 1.124e+05</td> <td> 6464.667</td> <td>   17.390</td> <td> 0.000</td> <td> 9.97e+04</td> <td> 1.25e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td> 1.957e+05</td> <td> 5998.199</td> <td>   32.632</td> <td> 0.000</td> <td> 1.84e+05</td> <td> 2.07e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td> 2.208e+05</td> <td> 7588.750</td> <td>   29.091</td> <td> 0.000</td> <td> 2.06e+05</td> <td> 2.36e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td> 2.826e+05</td> <td> 6814.830</td> <td>   41.470</td> <td> 0.000</td> <td> 2.69e+05</td> <td> 2.96e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td> 4.952e+05</td> <td> 9408.148</td> <td>   52.636</td> <td> 0.000</td> <td> 4.77e+05</td> <td> 5.14e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td> 7.336e+05</td> <td> 1.19e+04</td> <td>   61.562</td> <td> 0.000</td> <td>  7.1e+05</td> <td> 7.57e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td> 1.233e+06</td> <td> 2.72e+04</td> <td>   45.309</td> <td> 0.000</td> <td> 1.18e+06</td> <td> 1.29e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>   <td> 2.294e+04</td> <td> 1.35e+04</td> <td>    1.699</td> <td> 0.089</td> <td>-3529.363</td> <td> 4.94e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>   <td> 8.975e+04</td> <td> 1.41e+04</td> <td>    6.349</td> <td> 0.000</td> <td>  6.2e+04</td> <td> 1.17e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>   <td>  2.16e+05</td> <td> 1.12e+04</td> <td>   19.302</td> <td> 0.000</td> <td> 1.94e+05</td> <td> 2.38e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>   <td> 5.586e+05</td> <td> 2.14e+04</td> <td>   26.136</td> <td> 0.000</td> <td> 5.17e+05</td> <td>    6e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>   <td> 1.638e+06</td> <td> 5.01e+04</td> <td>   32.716</td> <td> 0.000</td> <td> 1.54e+06</td> <td> 1.74e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>   <td>-3.156e+05</td> <td> 9424.761</td> <td>  -33.485</td> <td> 0.000</td> <td>-3.34e+05</td> <td>-2.97e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>   <td>-2.966e+05</td> <td> 7597.782</td> <td>  -39.033</td> <td> 0.000</td> <td>-3.11e+05</td> <td>-2.82e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>   <td>-2.592e+05</td> <td> 6859.213</td> <td>  -37.784</td> <td> 0.000</td> <td>-2.73e+05</td> <td>-2.46e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>   <td>-1.575e+05</td> <td> 6770.315</td> <td>  -23.269</td> <td> 0.000</td> <td>-1.71e+05</td> <td>-1.44e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>   <td> 8.808e+04</td> <td> 5467.665</td> <td>   16.109</td> <td> 0.000</td> <td> 7.74e+04</td> <td> 9.88e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x49</th>   <td> 1.765e+05</td> <td> 8532.261</td> <td>   20.687</td> <td> 0.000</td> <td>  1.6e+05</td> <td> 1.93e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x50</th>   <td> 3.556e+05</td> <td> 1.33e+04</td> <td>   26.728</td> <td> 0.000</td> <td>  3.3e+05</td> <td> 3.82e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x51</th>   <td>-7244.5515</td> <td> 3296.817</td> <td>   -2.197</td> <td> 0.028</td> <td>-1.37e+04</td> <td> -782.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x52</th>   <td> 3.335e+04</td> <td> 6315.892</td> <td>    5.281</td> <td> 0.000</td> <td>  2.1e+04</td> <td> 4.57e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x53</th>   <td> 4.833e+05</td> <td> 1.93e+04</td> <td>   25.085</td> <td> 0.000</td> <td> 4.46e+05</td> <td> 5.21e+05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>7983.271</td> <th>  Durbin-Watson:     </th>  <td>   2.013</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>433780.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 1.912</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>29.560</td>  <th>  Cond. No.          </th>  <td>    348.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.831\n",
       "Model:                            OLS   Adj. R-squared:                  0.830\n",
       "Method:                 Least Squares   F-statistic:                     1334.\n",
       "Date:                Sat, 27 Jun 2020   Prob (F-statistic):               0.00\n",
       "Time:                        15:37:02   Log-Likelihood:            -1.9287e+05\n",
       "No. Observations:               14458   AIC:                         3.859e+05\n",
       "Df Residuals:                   14404   BIC:                         3.863e+05\n",
       "Df Model:                          53                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       6.323e+05   7.89e+04      8.018      0.000    4.78e+05    7.87e+05\n",
       "x1          7.405e+04   9091.486      8.145      0.000    5.62e+04    9.19e+04\n",
       "x2          1.951e+04   8826.793      2.210      0.027    2208.616    3.68e+04\n",
       "x3          8225.2209   1334.120      6.165      0.000    5610.173    1.08e+04\n",
       "x4          2.539e+04   2130.881     11.913      0.000    2.12e+04    2.96e+04\n",
       "x5         -2.387e+04   1703.360    -14.013      0.000   -2.72e+04   -2.05e+04\n",
       "x6         -1.219e+04   1.63e+04     -0.748      0.454   -4.41e+04    1.97e+04\n",
       "x7         -1.035e+04    1.9e+04     -0.546      0.585   -4.76e+04    2.68e+04\n",
       "x8         -2.264e+04   2.04e+04     -1.110      0.267   -6.26e+04    1.74e+04\n",
       "x9         -3.044e+04   2.24e+04     -1.361      0.173   -7.43e+04    1.34e+04\n",
       "x10        -7.667e+04   2.57e+04     -2.988      0.003   -1.27e+05   -2.64e+04\n",
       "x11         1.924e+04   7.57e+04      0.254      0.799   -1.29e+05    1.68e+05\n",
       "x12         -868.2025   7.66e+04     -0.011      0.991   -1.51e+05    1.49e+05\n",
       "x13         1.941e+04   7.72e+04      0.252      0.801   -1.32e+05    1.71e+05\n",
       "x14         9.842e+04   7.79e+04      1.264      0.206   -5.42e+04    2.51e+05\n",
       "x15         1.953e+05   7.85e+04      2.489      0.013    4.15e+04    3.49e+05\n",
       "x16         5.558e+05   8.15e+04      6.820      0.000    3.96e+05    7.16e+05\n",
       "x17         2.516e+06   1.24e+05     20.293      0.000    2.27e+06    2.76e+06\n",
       "x18         1.371e+04   8907.656      1.539      0.124   -3748.091    3.12e+04\n",
       "x19         1.562e+04   1.13e+04      1.386      0.166   -6472.610    3.77e+04\n",
       "x20         7612.1944   1.32e+04      0.578      0.563   -1.82e+04    3.34e+04\n",
       "x21         3322.1294   1.88e+04      0.177      0.860   -3.35e+04    4.02e+04\n",
       "x22        -5.011e+04   5.21e+04     -0.961      0.337   -1.52e+05    5.21e+04\n",
       "x23         2.456e+04   1.25e+04      1.968      0.049     102.411     4.9e+04\n",
       "x24         1.275e+05   2.36e+04      5.401      0.000    8.12e+04    1.74e+05\n",
       "x25          1.17e+04   2.24e+04      0.522      0.601   -3.22e+04    5.56e+04\n",
       "x26        -6.538e+04   4711.110    -13.877      0.000   -7.46e+04   -5.61e+04\n",
       "x27        -9.697e+04   5644.136    -17.180      0.000   -1.08e+05   -8.59e+04\n",
       "x28        -1.227e+05   7836.165    -15.655      0.000   -1.38e+05   -1.07e+05\n",
       "x29        -1.148e+05   8468.126    -13.551      0.000   -1.31e+05   -9.82e+04\n",
       "x30        -6.829e+04   1.03e+04     -6.650      0.000   -8.84e+04   -4.82e+04\n",
       "x31         5.401e+04   4614.921     11.704      0.000     4.5e+04    6.31e+04\n",
       "x32         1.124e+05   6464.667     17.390      0.000    9.97e+04    1.25e+05\n",
       "x33         1.957e+05   5998.199     32.632      0.000    1.84e+05    2.07e+05\n",
       "x34         2.208e+05   7588.750     29.091      0.000    2.06e+05    2.36e+05\n",
       "x35         2.826e+05   6814.830     41.470      0.000    2.69e+05    2.96e+05\n",
       "x36         4.952e+05   9408.148     52.636      0.000    4.77e+05    5.14e+05\n",
       "x37         7.336e+05   1.19e+04     61.562      0.000     7.1e+05    7.57e+05\n",
       "x38         1.233e+06   2.72e+04     45.309      0.000    1.18e+06    1.29e+06\n",
       "x39         2.294e+04   1.35e+04      1.699      0.089   -3529.363    4.94e+04\n",
       "x40         8.975e+04   1.41e+04      6.349      0.000     6.2e+04    1.17e+05\n",
       "x41          2.16e+05   1.12e+04     19.302      0.000    1.94e+05    2.38e+05\n",
       "x42         5.586e+05   2.14e+04     26.136      0.000    5.17e+05       6e+05\n",
       "x43         1.638e+06   5.01e+04     32.716      0.000    1.54e+06    1.74e+06\n",
       "x44        -3.156e+05   9424.761    -33.485      0.000   -3.34e+05   -2.97e+05\n",
       "x45        -2.966e+05   7597.782    -39.033      0.000   -3.11e+05   -2.82e+05\n",
       "x46        -2.592e+05   6859.213    -37.784      0.000   -2.73e+05   -2.46e+05\n",
       "x47        -1.575e+05   6770.315    -23.269      0.000   -1.71e+05   -1.44e+05\n",
       "x48         8.808e+04   5467.665     16.109      0.000    7.74e+04    9.88e+04\n",
       "x49         1.765e+05   8532.261     20.687      0.000     1.6e+05    1.93e+05\n",
       "x50         3.556e+05   1.33e+04     26.728      0.000     3.3e+05    3.82e+05\n",
       "x51        -7244.5515   3296.817     -2.197      0.028   -1.37e+04    -782.366\n",
       "x52         3.335e+04   6315.892      5.281      0.000     2.1e+04    4.57e+04\n",
       "x53         4.833e+05   1.93e+04     25.085      0.000    4.46e+05    5.21e+05\n",
       "==============================================================================\n",
       "Omnibus:                     7983.271   Durbin-Watson:                   2.013\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           433780.013\n",
       "Skew:                           1.912   Prob(JB):                         0.00\n",
       "Kurtosis:                      29.560   Cond. No.                         348.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regressor = OLS(y_fit, add_constant(X_fit.toarray()))\n",
    "results = linear_regressor.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach with `PolynomialFeatures`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2:   0.927, 0.814\n",
      "RMSE:  98616, 164623\n",
      "MAE:   65636, 83534\n",
      "MedAE: 44483, 46359\n",
      "MAPE:  0.134, 0.149\n"
     ]
    }
   ],
   "source": [
    "polynomial_regressor = make_pipeline(PolynomialFeatures(), LinearRegression())\n",
    "polynomial_regressor.fit(X_fit, y_fit);\n",
    "print_evaluation(polynomial_regressor, X_fit, X_valid, y_fit, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logarithmic approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2:   0.867, 0.871\n",
      "RMSE:  133157, 136845\n",
      "MAE:   78836, 80706\n",
      "MedAE: 49361, 48743\n",
      "MAPE:  0.147, 0.144\n"
     ]
    }
   ],
   "source": [
    "linear_regressor = TransformedTargetRegressor(regressor=LinearRegression(), func=np.log, inverse_func=np.exp)\n",
    "linear_regressor.fit(X_fit, y_fit)\n",
    "print_evaluation(linear_regressor, X_fit, X_valid, y_fit, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.864</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.864</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1732.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 27 Jun 2020</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:37:13</td>     <th>  Log-Likelihood:    </th> <td>  3221.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 14458</td>      <th>  AIC:               </th> <td>  -6335.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 14404</td>      <th>  BIC:               </th> <td>  -5926.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    53</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   12.6453</td> <td>    0.101</td> <td>  124.595</td> <td> 0.000</td> <td>   12.446</td> <td>   12.844</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.1368</td> <td>    0.012</td> <td>   11.691</td> <td> 0.000</td> <td>    0.114</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0528</td> <td>    0.011</td> <td>    4.643</td> <td> 0.000</td> <td>    0.030</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0300</td> <td>    0.002</td> <td>   17.484</td> <td> 0.000</td> <td>    0.027</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0583</td> <td>    0.003</td> <td>   21.246</td> <td> 0.000</td> <td>    0.053</td> <td>    0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.0435</td> <td>    0.002</td> <td>  -19.847</td> <td> 0.000</td> <td>   -0.048</td> <td>   -0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.0057</td> <td>    0.021</td> <td>    0.271</td> <td> 0.787</td> <td>   -0.035</td> <td>    0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.0182</td> <td>    0.024</td> <td>    0.743</td> <td> 0.457</td> <td>   -0.030</td> <td>    0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0102</td> <td>    0.026</td> <td>    0.389</td> <td> 0.697</td> <td>   -0.041</td> <td>    0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.0068</td> <td>    0.029</td> <td>   -0.236</td> <td> 0.814</td> <td>   -0.063</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0269</td> <td>    0.033</td> <td>   -0.815</td> <td> 0.415</td> <td>   -0.092</td> <td>    0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.1774</td> <td>    0.097</td> <td>    1.821</td> <td> 0.069</td> <td>   -0.014</td> <td>    0.368</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.1400</td> <td>    0.099</td> <td>    1.420</td> <td> 0.155</td> <td>   -0.053</td> <td>    0.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    0.1594</td> <td>    0.099</td> <td>    1.606</td> <td> 0.108</td> <td>   -0.035</td> <td>    0.354</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    0.2077</td> <td>    0.100</td> <td>    2.072</td> <td> 0.038</td> <td>    0.011</td> <td>    0.404</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>    0.2444</td> <td>    0.101</td> <td>    2.420</td> <td> 0.016</td> <td>    0.046</td> <td>    0.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    0.2842</td> <td>    0.105</td> <td>    2.709</td> <td> 0.007</td> <td>    0.079</td> <td>    0.490</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    0.2352</td> <td>    0.160</td> <td>    1.474</td> <td> 0.141</td> <td>   -0.078</td> <td>    0.548</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    0.0579</td> <td>    0.011</td> <td>    5.047</td> <td> 0.000</td> <td>    0.035</td> <td>    0.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>    0.0697</td> <td>    0.015</td> <td>    4.808</td> <td> 0.000</td> <td>    0.041</td> <td>    0.098</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>    0.0686</td> <td>    0.017</td> <td>    4.051</td> <td> 0.000</td> <td>    0.035</td> <td>    0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.0625</td> <td>    0.024</td> <td>    2.585</td> <td> 0.010</td> <td>    0.015</td> <td>    0.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>    0.0198</td> <td>    0.067</td> <td>    0.296</td> <td> 0.767</td> <td>   -0.112</td> <td>    0.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>    0.0685</td> <td>    0.016</td> <td>    4.268</td> <td> 0.000</td> <td>    0.037</td> <td>    0.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>    0.1240</td> <td>    0.030</td> <td>    4.081</td> <td> 0.000</td> <td>    0.064</td> <td>    0.184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>    0.0575</td> <td>    0.029</td> <td>    1.995</td> <td> 0.046</td> <td>    0.001</td> <td>    0.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>   -0.1178</td> <td>    0.006</td> <td>  -19.435</td> <td> 0.000</td> <td>   -0.130</td> <td>   -0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>   -0.1595</td> <td>    0.007</td> <td>  -21.958</td> <td> 0.000</td> <td>   -0.174</td> <td>   -0.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>   -0.1698</td> <td>    0.010</td> <td>  -16.839</td> <td> 0.000</td> <td>   -0.190</td> <td>   -0.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>   -0.1723</td> <td>    0.011</td> <td>  -15.805</td> <td> 0.000</td> <td>   -0.194</td> <td>   -0.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>   -0.0962</td> <td>    0.013</td> <td>   -7.282</td> <td> 0.000</td> <td>   -0.122</td> <td>   -0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>    0.1815</td> <td>    0.006</td> <td>   30.563</td> <td> 0.000</td> <td>    0.170</td> <td>    0.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>    0.3240</td> <td>    0.008</td> <td>   38.941</td> <td> 0.000</td> <td>    0.308</td> <td>    0.340</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>    0.4988</td> <td>    0.008</td> <td>   64.610</td> <td> 0.000</td> <td>    0.484</td> <td>    0.514</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td>    0.5212</td> <td>    0.010</td> <td>   53.365</td> <td> 0.000</td> <td>    0.502</td> <td>    0.540</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>    0.6067</td> <td>    0.009</td> <td>   69.176</td> <td> 0.000</td> <td>    0.590</td> <td>    0.624</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>    0.7892</td> <td>    0.012</td> <td>   65.174</td> <td> 0.000</td> <td>    0.765</td> <td>    0.813</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td>    1.0119</td> <td>    0.015</td> <td>   65.979</td> <td> 0.000</td> <td>    0.982</td> <td>    1.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td>    1.1830</td> <td>    0.035</td> <td>   33.784</td> <td> 0.000</td> <td>    1.114</td> <td>    1.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>   <td>    0.1591</td> <td>    0.017</td> <td>    9.155</td> <td> 0.000</td> <td>    0.125</td> <td>    0.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>   <td>    0.2482</td> <td>    0.018</td> <td>   13.642</td> <td> 0.000</td> <td>    0.213</td> <td>    0.284</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>   <td>    0.1161</td> <td>    0.014</td> <td>    8.059</td> <td> 0.000</td> <td>    0.088</td> <td>    0.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>   <td>    0.2372</td> <td>    0.028</td> <td>    8.622</td> <td> 0.000</td> <td>    0.183</td> <td>    0.291</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>   <td>    0.5951</td> <td>    0.064</td> <td>    9.236</td> <td> 0.000</td> <td>    0.469</td> <td>    0.721</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>   <td>   -0.4484</td> <td>    0.012</td> <td>  -36.966</td> <td> 0.000</td> <td>   -0.472</td> <td>   -0.425</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>   <td>   -0.3382</td> <td>    0.010</td> <td>  -34.585</td> <td> 0.000</td> <td>   -0.357</td> <td>   -0.319</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>   <td>   -0.2429</td> <td>    0.009</td> <td>  -27.510</td> <td> 0.000</td> <td>   -0.260</td> <td>   -0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>   <td>   -0.1103</td> <td>    0.009</td> <td>  -12.663</td> <td> 0.000</td> <td>   -0.127</td> <td>   -0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>   <td>    0.1459</td> <td>    0.007</td> <td>   20.736</td> <td> 0.000</td> <td>    0.132</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x49</th>   <td>    0.2136</td> <td>    0.011</td> <td>   19.451</td> <td> 0.000</td> <td>    0.192</td> <td>    0.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x50</th>   <td>    0.3421</td> <td>    0.017</td> <td>   19.978</td> <td> 0.000</td> <td>    0.309</td> <td>    0.376</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x51</th>   <td>   -0.0172</td> <td>    0.004</td> <td>   -4.047</td> <td> 0.000</td> <td>   -0.025</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x52</th>   <td>    0.0442</td> <td>    0.008</td> <td>    5.434</td> <td> 0.000</td> <td>    0.028</td> <td>    0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x53</th>   <td>    0.4143</td> <td>    0.025</td> <td>   16.707</td> <td> 0.000</td> <td>    0.366</td> <td>    0.463</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>738.949</td> <th>  Durbin-Watson:     </th> <td>   2.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2725.995</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.099</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.118</td>  <th>  Cond. No.          </th> <td>    348.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.864\n",
       "Model:                            OLS   Adj. R-squared:                  0.864\n",
       "Method:                 Least Squares   F-statistic:                     1732.\n",
       "Date:                Sat, 27 Jun 2020   Prob (F-statistic):               0.00\n",
       "Time:                        15:37:13   Log-Likelihood:                 3221.6\n",
       "No. Observations:               14458   AIC:                            -6335.\n",
       "Df Residuals:                   14404   BIC:                            -5926.\n",
       "Df Model:                          53                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         12.6453      0.101    124.595      0.000      12.446      12.844\n",
       "x1             0.1368      0.012     11.691      0.000       0.114       0.160\n",
       "x2             0.0528      0.011      4.643      0.000       0.030       0.075\n",
       "x3             0.0300      0.002     17.484      0.000       0.027       0.033\n",
       "x4             0.0583      0.003     21.246      0.000       0.053       0.064\n",
       "x5            -0.0435      0.002    -19.847      0.000      -0.048      -0.039\n",
       "x6             0.0057      0.021      0.271      0.787      -0.035       0.047\n",
       "x7             0.0182      0.024      0.743      0.457      -0.030       0.066\n",
       "x8             0.0102      0.026      0.389      0.697      -0.041       0.062\n",
       "x9            -0.0068      0.029     -0.236      0.814      -0.063       0.050\n",
       "x10           -0.0269      0.033     -0.815      0.415      -0.092       0.038\n",
       "x11            0.1774      0.097      1.821      0.069      -0.014       0.368\n",
       "x12            0.1400      0.099      1.420      0.155      -0.053       0.333\n",
       "x13            0.1594      0.099      1.606      0.108      -0.035       0.354\n",
       "x14            0.2077      0.100      2.072      0.038       0.011       0.404\n",
       "x15            0.2444      0.101      2.420      0.016       0.046       0.442\n",
       "x16            0.2842      0.105      2.709      0.007       0.079       0.490\n",
       "x17            0.2352      0.160      1.474      0.141      -0.078       0.548\n",
       "x18            0.0579      0.011      5.047      0.000       0.035       0.080\n",
       "x19            0.0697      0.015      4.808      0.000       0.041       0.098\n",
       "x20            0.0686      0.017      4.051      0.000       0.035       0.102\n",
       "x21            0.0625      0.024      2.585      0.010       0.015       0.110\n",
       "x22            0.0198      0.067      0.296      0.767      -0.112       0.151\n",
       "x23            0.0685      0.016      4.268      0.000       0.037       0.100\n",
       "x24            0.1240      0.030      4.081      0.000       0.064       0.184\n",
       "x25            0.0575      0.029      1.995      0.046       0.001       0.114\n",
       "x26           -0.1178      0.006    -19.435      0.000      -0.130      -0.106\n",
       "x27           -0.1595      0.007    -21.958      0.000      -0.174      -0.145\n",
       "x28           -0.1698      0.010    -16.839      0.000      -0.190      -0.150\n",
       "x29           -0.1723      0.011    -15.805      0.000      -0.194      -0.151\n",
       "x30           -0.0962      0.013     -7.282      0.000      -0.122      -0.070\n",
       "x31            0.1815      0.006     30.563      0.000       0.170       0.193\n",
       "x32            0.3240      0.008     38.941      0.000       0.308       0.340\n",
       "x33            0.4988      0.008     64.610      0.000       0.484       0.514\n",
       "x34            0.5212      0.010     53.365      0.000       0.502       0.540\n",
       "x35            0.6067      0.009     69.176      0.000       0.590       0.624\n",
       "x36            0.7892      0.012     65.174      0.000       0.765       0.813\n",
       "x37            1.0119      0.015     65.979      0.000       0.982       1.042\n",
       "x38            1.1830      0.035     33.784      0.000       1.114       1.252\n",
       "x39            0.1591      0.017      9.155      0.000       0.125       0.193\n",
       "x40            0.2482      0.018     13.642      0.000       0.213       0.284\n",
       "x41            0.1161      0.014      8.059      0.000       0.088       0.144\n",
       "x42            0.2372      0.028      8.622      0.000       0.183       0.291\n",
       "x43            0.5951      0.064      9.236      0.000       0.469       0.721\n",
       "x44           -0.4484      0.012    -36.966      0.000      -0.472      -0.425\n",
       "x45           -0.3382      0.010    -34.585      0.000      -0.357      -0.319\n",
       "x46           -0.2429      0.009    -27.510      0.000      -0.260      -0.226\n",
       "x47           -0.1103      0.009    -12.663      0.000      -0.127      -0.093\n",
       "x48            0.1459      0.007     20.736      0.000       0.132       0.160\n",
       "x49            0.2136      0.011     19.451      0.000       0.192       0.235\n",
       "x50            0.3421      0.017     19.978      0.000       0.309       0.376\n",
       "x51           -0.0172      0.004     -4.047      0.000      -0.025      -0.009\n",
       "x52            0.0442      0.008      5.434      0.000       0.028       0.060\n",
       "x53            0.4143      0.025     16.707      0.000       0.366       0.463\n",
       "==============================================================================\n",
       "Omnibus:                      738.949   Durbin-Watson:                   2.003\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2725.995\n",
       "Skew:                          -0.099   Prob(JB):                         0.00\n",
       "Kurtosis:                       5.118   Cond. No.                         348.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regressor = OLS(np.log(y_fit), add_constant(X_fit.toarray()))\n",
    "results = linear_regressor.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logarithmic approach with `PolynomialFeatures`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2:   0.927, 0.630\n",
      "RMSE:  98520, 232096\n",
      "MAE:   62989, 83388\n",
      "MedAE: 41215, 42813\n",
      "MAPE:  0.124, 0.138\n"
     ]
    }
   ],
   "source": [
    "polynomial_regressor = TransformedTargetRegressor(regressor=make_pipeline(PolynomialFeatures(),\n",
    "                                                                          LinearRegression()),\n",
    "                                                  func=np.log, inverse_func=np.exp)\n",
    "polynomial_regressor.fit(X_fit, y_fit)\n",
    "print_evaluation(polynomial_regressor, X_fit, X_valid, y_fit, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logarithmic approach with `SVR`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2:   0.935, 0.835\n",
      "RMSE:  93281, 154721\n",
      "MAE:   56526, 71248\n",
      "MedAE: 37425, 39507\n",
      "MAPE:  0.110, 0.125\n"
     ]
    }
   ],
   "source": [
    "support_vector_regressor = TransformedTargetRegressor(regressor=SVR(), func=np.log, inverse_func=np.exp)\n",
    "support_vector_regressor.fit(X_fit, y_fit)\n",
    "print_evaluation(support_vector_regressor, X_fit, X_valid, y_fit, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logarithmic approach with `RandomForestRegressor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2:   0.978, 0.886\n",
      "RMSE:  53779, 128805\n",
      "MAE:   27220, 68809\n",
      "MedAE: 14745, 38189\n",
      "MAPE:  0.048, 0.122\n"
     ]
    }
   ],
   "source": [
    "random_forest_regressor = TransformedTargetRegressor(regressor=RandomForestRegressor(), func=np.log,\n",
    "                                                     inverse_func=np.exp)\n",
    "random_forest_regressor.fit(X_fit, y_fit)\n",
    "print_evaluation(random_forest_regressor, X_fit, X_valid, y_fit, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logarithmic approach with `XGBRegressor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2:   0.967, 0.881\n",
      "RMSE:  66188, 131726\n",
      "MAE:   42829, 64983\n",
      "MedAE: 27838, 35410\n",
      "MAPE:  0.084, 0.117\n"
     ]
    }
   ],
   "source": [
    "xgb_regressor = TransformedTargetRegressor(regressor=XGBRegressor(), func=np.log, inverse_func=np.exp)\n",
    "xgb_regressor.fit(X_fit, y_fit)\n",
    "print_evaluation(xgb_regressor, X_fit, X_valid, y_fit, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 components\n",
      "R^2:   0.848, 0.839\n",
      "RMSE:  142742, 153220\n",
      "MAE:   86861, 89670\n",
      "MedAE: 55861, 54205\n",
      "MAPE:  0.164, 0.159\n",
      "2 components\n",
      "R^2:   0.863, 0.867\n",
      "RMSE:  135448, 139272\n",
      "MAE:   80867, 82599\n",
      "MedAE: 49914, 48384\n",
      "MAPE:  0.151, 0.146\n",
      "3 components\n",
      "R^2:   0.862, 0.865\n",
      "RMSE:  135634, 140008\n",
      "MAE:   80561, 82016\n",
      "MedAE: 49403, 47475\n",
      "MAPE:  0.149, 0.144\n",
      "4 components\n",
      "R^2:   0.867, 0.869\n",
      "RMSE:  133434, 137975\n",
      "MAE:   78967, 81125\n",
      "MedAE: 49466, 48922\n",
      "MAPE:  0.147, 0.144\n",
      "5 components\n",
      "R^2:   0.867, 0.871\n",
      "RMSE:  133157, 136846\n",
      "MAE:   78836, 80706\n",
      "MedAE: 49359, 48743\n",
      "MAPE:  0.147, 0.144\n"
     ]
    }
   ],
   "source": [
    "for idx in range(1, len(numerical_features) + 1):\n",
    "    print('{} components'.format(idx))\n",
    "    linear_regressor = TransformedTargetRegressor(\n",
    "        make_pipeline(\n",
    "            ColumnTransformer([\n",
    "                ('numericals_transformer', make_pipeline(StandardScaler(), PCA(idx)), numerical_features),\n",
    "                ('categoricals_transformer', OneHotEncoder(drop='first'), categorical_features),\n",
    "                ('booleans_transformer', 'passthrough', boolean_features)\n",
    "            ], n_jobs=-1),\n",
    "            LinearRegression()),\n",
    "        func=np.log, inverse_func=np.exp)\n",
    "    linear_regressor.fit(houses_fit, y_fit);\n",
    "    print_evaluation(linear_regressor, houses_fit, houses_valid, y_fit, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 components\n",
      "R^2:   0.904, 0.733\n",
      "RMSE:  113125, 196991\n",
      "MAE:   73931, 90457\n",
      "MedAE: 49833, 53644\n",
      "MAPE:  0.146, 0.157\n",
      "2 components\n",
      "R^2:   0.917, 0.848\n",
      "RMSE:  105402, 148867\n",
      "MAE:   67635, 80679\n",
      "MedAE: 43695, 44644\n",
      "MAPE:  0.132, 0.142\n",
      "3 components\n",
      "R^2:   0.920, 0.751\n",
      "RMSE:  103578, 190203\n",
      "MAE:   65990, 83499\n",
      "MedAE: 42790, 43527\n",
      "MAPE:  0.129, 0.142\n",
      "4 components\n",
      "R^2:   0.926, 0.728\n",
      "RMSE:  99505, 199023\n",
      "MAE:   63361, 81738\n",
      "MedAE: 41185, 42153\n",
      "MAPE:  0.125, 0.138\n",
      "5 components\n",
      "R^2:   0.927, 0.633\n",
      "RMSE:  98523, 231161\n",
      "MAE:   62993, 83332\n",
      "MedAE: 41233, 42708\n",
      "MAPE:  0.124, 0.138\n"
     ]
    }
   ],
   "source": [
    "for idx in range(1, len(numerical_features) + 1):\n",
    "    print('{} components'.format(idx))\n",
    "    polynomial_regressor = TransformedTargetRegressor(\n",
    "        make_pipeline(\n",
    "            ColumnTransformer([\n",
    "                ('numericals_transformer', make_pipeline(StandardScaler(), PCA(idx)), numerical_features),\n",
    "                ('categoricals_transformer', OneHotEncoder(drop='first'), categorical_features),\n",
    "                ('booleans_transformer', 'passthrough', boolean_features)\n",
    "            ], n_jobs=-1),\n",
    "            PolynomialFeatures(),\n",
    "            LinearRegression()),\n",
    "        func=np.log, inverse_func=np.exp)\n",
    "    polynomial_regressor.fit(houses_fit, y_fit);\n",
    "    print_evaluation(polynomial_regressor, houses_fit, houses_valid, y_fit, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 components\n",
      "R^2:   0.911, 0.785\n",
      "RMSE:  109368, 176813\n",
      "MAE:   67552, 84920\n",
      "MedAE: 45843, 48689\n",
      "MAPE:  0.133, 0.150\n",
      "2 components\n",
      "R^2:   0.928, 0.822\n",
      "RMSE:  98404, 160860\n",
      "MAE:   60677, 76534\n",
      "MedAE: 40474, 43034\n",
      "MAPE:  0.118, 0.134\n",
      "3 components\n",
      "R^2:   0.931, 0.834\n",
      "RMSE:  95951, 155298\n",
      "MAE:   58132, 73026\n",
      "MedAE: 38428, 40540\n",
      "MAPE:  0.112, 0.128\n",
      "4 components\n",
      "R^2:   0.935, 0.842\n",
      "RMSE:  93149, 151481\n",
      "MAE:   56321, 70680\n",
      "MedAE: 37062, 38570\n",
      "MAPE:  0.109, 0.124\n",
      "5 components\n",
      "R^2:   0.936, 0.844\n",
      "RMSE:  92351, 150845\n",
      "MAE:   56168, 70550\n",
      "MedAE: 37163, 38845\n",
      "MAPE:  0.109, 0.124\n"
     ]
    }
   ],
   "source": [
    "for idx in range(1, len(numerical_features) + 1):\n",
    "    print('{} components'.format(idx))\n",
    "    xgb_regressor = TransformedTargetRegressor(\n",
    "        make_pipeline(\n",
    "            ColumnTransformer([\n",
    "                ('numericals_transformer', make_pipeline(StandardScaler(), PCA(idx)), numerical_features),\n",
    "                ('categoricals_transformer', OneHotEncoder(), categorical_features),\n",
    "                ('booleans_transformer', 'passthrough', boolean_features)\n",
    "            ], n_jobs=-1),\n",
    "            SVR()),\n",
    "        func=np.log, inverse_func=np.exp)\n",
    "    xgb_regressor.fit(houses_fit, y_fit);\n",
    "    print_evaluation(xgb_regressor, houses_fit, houses_valid, y_fit, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Systematic analysis\n",
    "\n",
    "We conduct a systematic analysis by tuning the hyperparameters for several regressors using a randomized search (due to long computation time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_selection = [\n",
    "    ('sklearn.linear_model', 'LinearRegression', 'linear_regressor',\n",
    "     {\n",
    "         'fit_intercept': [True, False],\n",
    "         'normalize':     [True, False]\n",
    "     }),\n",
    "    ('sklearn.linear_model', 'ElasticNet', 'elastic_net_regressor',\n",
    "     {\n",
    "         'alpha':         [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0],\n",
    "         'l1_ratio':      [r*0.1 for r in range(0, 11)],\n",
    "         'fit_intercept': [True, False],\n",
    "         'normalize':     [True, False],\n",
    "         'max_iter':      [1000, 2000],\n",
    "         'random_state':  [0]\n",
    "     }),\n",
    "    ('sklearn.linear_model', 'LinearRegression', 'polynomial_regressor',\n",
    "     {\n",
    "         'fit_intercept': [True, False],\n",
    "         'normalize':     [True, False]\n",
    "     }),\n",
    "    ('sklearn.linear_model', 'ElasticNet', 'polynomial_elastic_net_regressor',\n",
    "     {\n",
    "         'alpha':         [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0],\n",
    "         'l1_ratio':      [r*0.1 for r in range(0, 11)],\n",
    "         'fit_intercept': [True, False],\n",
    "         'normalize':     [True, False],\n",
    "         'max_iter':      [1000, 2000],\n",
    "         'random_state':  [0]\n",
    "     }),\n",
    "    ('sklearn.neighbors', 'KNeighborsRegressor', 'k_nearest_neighbors_regressor',\n",
    "     {\n",
    "         'n_neighbors': list(range(1, 21)),\n",
    "         'leaf_size':   list(range(15, 55)),\n",
    "         'p':           [1, 2]\n",
    "     }),\n",
    "    ('sklearn.svm', 'SVR', 'linear_support_vector_regressor',\n",
    "     {\n",
    "         'kernel':       ['linear'],\n",
    "         'C':            [10**r for r in range(-5, 1)],\n",
    "         'shrinking':    [True, False]\n",
    "     }),\n",
    "    ('sklearn.svm', 'SVR', 'poly_support_vector_regressor',\n",
    "     {\n",
    "         'kernel':       ['poly'],\n",
    "         'degree':       [2, 3],\n",
    "         'C':            [10**r for r in range(-5, 1)],\n",
    "         'gamma':        [10**r for r in range(-5, 0)] + ['scale', 'auto'],\n",
    "         'shrinking':    [True, False]\n",
    "     }),\n",
    "    ('sklearn.svm', 'SVR', 'sigmoid_support_vector_regressor',\n",
    "     {\n",
    "         'kernel':       ['sigmoid'],\n",
    "         'C':            [10**r for r in range(-5, 4)],\n",
    "         'gamma':        [10**r for r in range(-5, 4)] + ['scale', 'auto'],\n",
    "         'shrinking':    [True, False]\n",
    "     }),\n",
    "    ('sklearn.svm', 'SVR', 'rbf_support_vector_regressor',\n",
    "     {\n",
    "         'kernel':       ['rbf'],\n",
    "         'C':            [10**r for r in range(-5, 4)],\n",
    "         'gamma':        [10**r for r in range(-5, 4)] + ['scale', 'auto'],\n",
    "         'shrinking':    [True, False]\n",
    "     }),\n",
    "    ('sklearn.tree', 'DecisionTreeRegressor', 'decision_tree_regressor',\n",
    "     {\n",
    "     # criterion='mae' is very slow:\n",
    "     # https://github.com/scikit-learn/scikit-learn/issues/9553#issuecomment-324484928\n",
    "         'splitter':          ['best', 'random'],\n",
    "         'max_depth':         list(range(5, 30)) + [None],\n",
    "         'min_samples_split': list(range(2, 11)),\n",
    "         'min_samples_leaf':  list(range(1, 11)),\n",
    "         'random_state':      [0]\n",
    "     }),\n",
    "    ('sklearn.ensemble', 'RandomForestRegressor', 'random_forest_regressor',\n",
    "     {\n",
    "         'n_estimators':      [100, 150, 200, 250],\n",
    "         'max_depth':         list(range(5, 30)) + [None],\n",
    "         'min_samples_split': list(range(2, 11)),\n",
    "         'min_samples_leaf':  list(range(1, 11)),\n",
    "         'random_state':      [0],\n",
    "         'n_jobs':            [-1]\n",
    "     }),\n",
    "    ('sklearn.ensemble', 'ExtraTreesRegressor', 'extra_trees_regressor',\n",
    "     {\n",
    "         'n_estimators':      [100, 150, 200, 250],\n",
    "         'max_depth':         list(range(5, 30)) + [None],\n",
    "         'min_samples_split': list(range(2, 11)),\n",
    "         'min_samples_leaf':  list(range(1, 11)),\n",
    "         'bootstrap':         [True, False],\n",
    "         'random_state':      [0],\n",
    "         'n_jobs':            [-1]\n",
    "     }),    \n",
    "    ('xgboost', 'XGBRegressor', 'xgb_regressor',\n",
    "     {\n",
    "         'n_estimators':      [80, 100, 120, 140, 160],\n",
    "         'max_depth':         [4, 6, 8, 10, 12, 14],\n",
    "         'learning_rate':     [0.01, 0.05, 0.10, 0.20, 0.30],\n",
    "         'min_child_weight':  [1, 3, 5],\n",
    "         'colsample_bytree':  [0.5, 0.6, 0.7, 0.8, 0.9, 1.],\n",
    "         'reg_alpha':         [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "         'reg_lambda':        [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "         'random_state':      [0],\n",
    "         'n_jobs':            [-1]\n",
    "    })\n",
    "]\n",
    "\n",
    "scorer = make_scorer(mean_absolute_percentage_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Module</th>\n",
       "      <th>Class</th>\n",
       "      <th>Name</th>\n",
       "      <th>BestParameters</th>\n",
       "      <th>BestScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>xgb_regressor</td>\n",
       "      <td>{'regressor__column_transformer__categoricals_...</td>\n",
       "      <td>-0.116407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>xgb_regressor</td>\n",
       "      <td>{'regressor__column_transformer__categoricals_...</td>\n",
       "      <td>-0.116407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>xgb_regressor</td>\n",
       "      <td>{'regressor__column_transformer__categoricals_...</td>\n",
       "      <td>-0.116407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>xgb_regressor</td>\n",
       "      <td>{'regressor__xgb_regressor__reg_lambda': 0.7, ...</td>\n",
       "      <td>-0.117111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sklearn.ensemble</td>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>extra_trees_regressor</td>\n",
       "      <td>{'regressor__extra_trees_regressor__random_sta...</td>\n",
       "      <td>-0.125521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sklearn.ensemble</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>random_forest_regressor</td>\n",
       "      <td>{'regressor__random_forest_regressor__random_s...</td>\n",
       "      <td>-0.126392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sklearn.svm</td>\n",
       "      <td>SVR</td>\n",
       "      <td>poly_support_vector_regressor</td>\n",
       "      <td>{'regressor__poly_support_vector_regressor__sh...</td>\n",
       "      <td>-0.134723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sklearn.svm</td>\n",
       "      <td>SVR</td>\n",
       "      <td>rbf_support_vector_regressor</td>\n",
       "      <td>{'regressor__rbf_support_vector_regressor__shr...</td>\n",
       "      <td>-0.134943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sklearn.linear_model</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>polynomial_elastic_net_regressor</td>\n",
       "      <td>{'regressor__polynomialiser__interaction_only'...</td>\n",
       "      <td>-0.136236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sklearn.linear_model</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>polynomial_regressor</td>\n",
       "      <td>{'regressor__polynomialiser__interaction_only'...</td>\n",
       "      <td>-0.142989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sklearn.linear_model</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>linear_regressor</td>\n",
       "      <td>{'regressor__linear_regressor__normalize': Fal...</td>\n",
       "      <td>-0.147419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sklearn.svm</td>\n",
       "      <td>SVR</td>\n",
       "      <td>linear_support_vector_regressor</td>\n",
       "      <td>{'regressor__linear_support_vector_regressor__...</td>\n",
       "      <td>-0.147555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sklearn.linear_model</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>elastic_net_regressor</td>\n",
       "      <td>{'regressor__elastic_net_regressor__random_sta...</td>\n",
       "      <td>-0.149368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sklearn.neighbors</td>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>k_nearest_neighbors_regressor</td>\n",
       "      <td>{'regressor__k_nearest_neighbors_regressor__p'...</td>\n",
       "      <td>-0.150561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sklearn.tree</td>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>decision_tree_regressor</td>\n",
       "      <td>{'regressor__decision_tree_regressor__splitter...</td>\n",
       "      <td>-0.154098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sklearn.svm</td>\n",
       "      <td>SVR</td>\n",
       "      <td>sigmoid_support_vector_regressor</td>\n",
       "      <td>{'regressor__sigmoid_support_vector_regressor_...</td>\n",
       "      <td>-0.157782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Module                  Class  \\\n",
       "13               xgboost           XGBRegressor   \n",
       "14               xgboost           XGBRegressor   \n",
       "15               xgboost           XGBRegressor   \n",
       "12               xgboost           XGBRegressor   \n",
       "11      sklearn.ensemble    ExtraTreesRegressor   \n",
       "10      sklearn.ensemble  RandomForestRegressor   \n",
       "6            sklearn.svm                    SVR   \n",
       "8            sklearn.svm                    SVR   \n",
       "3   sklearn.linear_model             ElasticNet   \n",
       "2   sklearn.linear_model       LinearRegression   \n",
       "0   sklearn.linear_model       LinearRegression   \n",
       "5            sklearn.svm                    SVR   \n",
       "1   sklearn.linear_model             ElasticNet   \n",
       "4      sklearn.neighbors    KNeighborsRegressor   \n",
       "9           sklearn.tree  DecisionTreeRegressor   \n",
       "7            sklearn.svm                    SVR   \n",
       "\n",
       "                                Name  \\\n",
       "13                     xgb_regressor   \n",
       "14                     xgb_regressor   \n",
       "15                     xgb_regressor   \n",
       "12                     xgb_regressor   \n",
       "11             extra_trees_regressor   \n",
       "10           random_forest_regressor   \n",
       "6      poly_support_vector_regressor   \n",
       "8       rbf_support_vector_regressor   \n",
       "3   polynomial_elastic_net_regressor   \n",
       "2               polynomial_regressor   \n",
       "0                   linear_regressor   \n",
       "5    linear_support_vector_regressor   \n",
       "1              elastic_net_regressor   \n",
       "4      k_nearest_neighbors_regressor   \n",
       "9            decision_tree_regressor   \n",
       "7   sigmoid_support_vector_regressor   \n",
       "\n",
       "                                       BestParameters  BestScore  \n",
       "13  {'regressor__column_transformer__categoricals_...  -0.116407  \n",
       "14  {'regressor__column_transformer__categoricals_...  -0.116407  \n",
       "15  {'regressor__column_transformer__categoricals_...  -0.116407  \n",
       "12  {'regressor__xgb_regressor__reg_lambda': 0.7, ...  -0.117111  \n",
       "11  {'regressor__extra_trees_regressor__random_sta...  -0.125521  \n",
       "10  {'regressor__random_forest_regressor__random_s...  -0.126392  \n",
       "6   {'regressor__poly_support_vector_regressor__sh...  -0.134723  \n",
       "8   {'regressor__rbf_support_vector_regressor__shr...  -0.134943  \n",
       "3   {'regressor__polynomialiser__interaction_only'...  -0.136236  \n",
       "2   {'regressor__polynomialiser__interaction_only'...  -0.142989  \n",
       "0   {'regressor__linear_regressor__normalize': Fal...  -0.147419  \n",
       "5   {'regressor__linear_support_vector_regressor__...  -0.147555  \n",
       "1   {'regressor__elastic_net_regressor__random_sta...  -0.149368  \n",
       "4   {'regressor__k_nearest_neighbors_regressor__p'...  -0.150561  \n",
       "9   {'regressor__decision_tree_regressor__splitter...  -0.154098  \n",
       "7   {'regressor__sigmoid_support_vector_regressor_...  -0.157782  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    regressor_comparison = pd.read_pickle('results/regressor_comparison.pickle')\n",
    "except FileNotFoundError:\n",
    "    regressor_comparison = pd.DataFrame(columns=['Module', 'Class', 'Name', 'BestParameters', 'BestScore'])\n",
    "\n",
    "    for (module_name, class_name, regressor_name, parameters) in regressor_selection:\n",
    "        print('Randomized search for {:<80}'.format(regressor_name))\n",
    "        \n",
    "        module_of_regressor = import_module(module_name)\n",
    "        class_of_regressor = getattr(module_of_regressor, class_name)\n",
    "        \n",
    "        regressor = TransformedTargetRegressor(Pipeline([\n",
    "            ('column_transformer', ColumnTransformer([\n",
    "                ('numericals_transformer', Pipeline([\n",
    "                    ('scaler', 'passthrough'),\n",
    "                    ('pca', 'passthrough')\n",
    "                ]), numerical_features),\n",
    "                ('categoricals_transformer', OneHotEncoder(), categorical_features),\n",
    "                ('booleans_transformer', 'passthrough', boolean_features)\n",
    "            ], n_jobs=-1)),\n",
    "            ('polynomialiser', 'passthrough'),\n",
    "            (regressor_name, class_of_regressor())\n",
    "        ]), func=np.log, inverse_func=np.exp)\n",
    "        \n",
    "        parameters = {regressor_name + '__' + param: parameters[param] for param in parameters.keys()}\n",
    "        \n",
    "        if regressor_name == 'linear_regressor':\n",
    "            parameters.update({\n",
    "                'column_transformer__numericals_transformer__scaler': [StandardScaler(), MaxAbsScaler(), Normalizer()],\n",
    "                'column_transformer__numericals_transformer__pca': ['passthrough'] + [PCA(n_components, random_state=0) for n_components in range(1, len(numerical_features) + 1)],\n",
    "                'column_transformer__categoricals_transformer__drop': ['first']\n",
    "            })\n",
    "        elif regressor_name == 'polynomial_regressor':\n",
    "            parameters.update({\n",
    "                'column_transformer__numericals_transformer__scaler': [StandardScaler(), MaxAbsScaler(), Normalizer()],\n",
    "                'column_transformer__numericals_transformer__pca': ['passthrough'] + [PCA(n_components, random_state=0) for n_components in range(1, len(numerical_features) + 1)],\n",
    "                'column_transformer__categoricals_transformer__drop': ['first'],\n",
    "                'polynomialiser':                                     [PolynomialFeatures()],\n",
    "                'polynomialiser__interaction_only':                   [True, False]\n",
    "            })\n",
    "        elif regressor_name == 'polynomial_elastic_net_regressor':\n",
    "            parameters.update({\n",
    "                'column_transformer__numericals_transformer__scaler': [StandardScaler(), MaxAbsScaler(), Normalizer()],\n",
    "                'column_transformer__numericals_transformer__pca': ['passthrough'] + [PCA(n_components, random_state=0) for n_components in range(1, len(numerical_features) + 1)],\n",
    "                'polynomialiser':                   [PolynomialFeatures()],\n",
    "                'polynomialiser__interaction_only': [True, False]\n",
    "            })\n",
    "        elif regressor_name in ['elastic_net_regressor', 'k_nearest_neighbors_regressor',\n",
    "                                'linear_support_vector_regressor', 'poly_support_vector_regressor',\n",
    "                                'sigmoid_support_vector_regressor', 'rbf_support_vector_regressor']:\n",
    "            parameters.update({\n",
    "                'column_transformer__numericals_transformer__scaler': [StandardScaler(), MaxAbsScaler(), Normalizer()],\n",
    "                'column_transformer__numericals_transformer__pca': ['passthrough'] + [PCA(n_components, random_state=0) for n_components in range(1, len(numerical_features) + 1)],\n",
    "            })\n",
    "        elif regressor_name in ['decision_tree_regressor', 'random_forest_regressor', 'extra_trees_regressor',\n",
    "                                'xgb_regressor']:\n",
    "            parameters.update({\n",
    "                'column_transformer__categoricals_transformer': [OneHotEncoder(), OrdinalEncoder()]\n",
    "            })\n",
    "        # usage of TransformedTargetRegressor necessitates prefix\n",
    "        parameters = {'regressor__' + param: parameters[param] for param in parameters.keys()}\n",
    "        \n",
    "        rs = RandomizedSearchCV(estimator=regressor, param_distributions=parameters, n_iter=100, \n",
    "                                scoring=scorer, cv=10, verbose=1, n_jobs=-1, random_state=0)\n",
    "        rs.fit(houses_train, y_train)\n",
    "\n",
    "        regressor_comparison = regressor_comparison.append({\n",
    "            'Module':         module_name,\n",
    "            'Class':          class_name,\n",
    "            'Name':           regressor_name,\n",
    "            'BestParameters': rs.best_params_,\n",
    "            'BestScore':      rs.best_score_\n",
    "        }, ignore_index=True)\n",
    "        \n",
    "        regressor_comparison.to_pickle(path='results/regressor_comparison.pickle')\n",
    "        regressor_comparison.to_csv(path_or_buf='results/regressor_comparison.csv', index=False)\n",
    "\n",
    "    regressor_comparison.to_pickle(path='results/regressor_comparison.pickle')\n",
    "    regressor_comparison.to_csv(path_or_buf='results/regressor_comparison.csv', index=False)\n",
    "\n",
    "regressor_comparison.sort_values(by='BestScore', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We optimise the XGBRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'regressor__xgb_regressor__reg_lambda': 0.7,\n",
       " 'regressor__xgb_regressor__reg_alpha': 0.6,\n",
       " 'regressor__xgb_regressor__random_state': 0,\n",
       " 'regressor__xgb_regressor__n_jobs': -1,\n",
       " 'regressor__xgb_regressor__n_estimators': 140,\n",
       " 'regressor__xgb_regressor__min_child_weight': 1,\n",
       " 'regressor__xgb_regressor__max_depth': 10,\n",
       " 'regressor__xgb_regressor__learning_rate': 0.1,\n",
       " 'regressor__xgb_regressor__colsample_bytree': 0.5,\n",
       " 'regressor__column_transformer__categoricals_transformer': OrdinalEncoder()}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_comparison.loc[12, 'BestParameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Module</th>\n",
       "      <th>Class</th>\n",
       "      <th>Name</th>\n",
       "      <th>BestParameters</th>\n",
       "      <th>BestScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>xgb_regressor</td>\n",
       "      <td>{'regressor__column_transformer__categoricals_...</td>\n",
       "      <td>-0.116407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>xgb_regressor</td>\n",
       "      <td>{'regressor__column_transformer__categoricals_...</td>\n",
       "      <td>-0.116407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>xgb_regressor</td>\n",
       "      <td>{'regressor__column_transformer__categoricals_...</td>\n",
       "      <td>-0.116407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>xgb_regressor</td>\n",
       "      <td>{'regressor__xgb_regressor__reg_lambda': 0.7, ...</td>\n",
       "      <td>-0.117111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sklearn.ensemble</td>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>extra_trees_regressor</td>\n",
       "      <td>{'regressor__extra_trees_regressor__random_sta...</td>\n",
       "      <td>-0.125521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sklearn.ensemble</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>random_forest_regressor</td>\n",
       "      <td>{'regressor__random_forest_regressor__random_s...</td>\n",
       "      <td>-0.126392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sklearn.svm</td>\n",
       "      <td>SVR</td>\n",
       "      <td>poly_support_vector_regressor</td>\n",
       "      <td>{'regressor__poly_support_vector_regressor__sh...</td>\n",
       "      <td>-0.134723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sklearn.svm</td>\n",
       "      <td>SVR</td>\n",
       "      <td>rbf_support_vector_regressor</td>\n",
       "      <td>{'regressor__rbf_support_vector_regressor__shr...</td>\n",
       "      <td>-0.134943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sklearn.linear_model</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>polynomial_elastic_net_regressor</td>\n",
       "      <td>{'regressor__polynomialiser__interaction_only'...</td>\n",
       "      <td>-0.136236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sklearn.linear_model</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>polynomial_regressor</td>\n",
       "      <td>{'regressor__polynomialiser__interaction_only'...</td>\n",
       "      <td>-0.142989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sklearn.linear_model</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>linear_regressor</td>\n",
       "      <td>{'regressor__linear_regressor__normalize': Fal...</td>\n",
       "      <td>-0.147419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sklearn.svm</td>\n",
       "      <td>SVR</td>\n",
       "      <td>linear_support_vector_regressor</td>\n",
       "      <td>{'regressor__linear_support_vector_regressor__...</td>\n",
       "      <td>-0.147555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sklearn.linear_model</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>elastic_net_regressor</td>\n",
       "      <td>{'regressor__elastic_net_regressor__random_sta...</td>\n",
       "      <td>-0.149368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sklearn.neighbors</td>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>k_nearest_neighbors_regressor</td>\n",
       "      <td>{'regressor__k_nearest_neighbors_regressor__p'...</td>\n",
       "      <td>-0.150561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sklearn.tree</td>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>decision_tree_regressor</td>\n",
       "      <td>{'regressor__decision_tree_regressor__splitter...</td>\n",
       "      <td>-0.154098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sklearn.svm</td>\n",
       "      <td>SVR</td>\n",
       "      <td>sigmoid_support_vector_regressor</td>\n",
       "      <td>{'regressor__sigmoid_support_vector_regressor_...</td>\n",
       "      <td>-0.157782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Module                  Class  \\\n",
       "13               xgboost           XGBRegressor   \n",
       "14               xgboost           XGBRegressor   \n",
       "15               xgboost           XGBRegressor   \n",
       "12               xgboost           XGBRegressor   \n",
       "11      sklearn.ensemble    ExtraTreesRegressor   \n",
       "10      sklearn.ensemble  RandomForestRegressor   \n",
       "6            sklearn.svm                    SVR   \n",
       "8            sklearn.svm                    SVR   \n",
       "3   sklearn.linear_model             ElasticNet   \n",
       "2   sklearn.linear_model       LinearRegression   \n",
       "0   sklearn.linear_model       LinearRegression   \n",
       "5            sklearn.svm                    SVR   \n",
       "1   sklearn.linear_model             ElasticNet   \n",
       "4      sklearn.neighbors    KNeighborsRegressor   \n",
       "9           sklearn.tree  DecisionTreeRegressor   \n",
       "7            sklearn.svm                    SVR   \n",
       "\n",
       "                                Name  \\\n",
       "13                     xgb_regressor   \n",
       "14                     xgb_regressor   \n",
       "15                     xgb_regressor   \n",
       "12                     xgb_regressor   \n",
       "11             extra_trees_regressor   \n",
       "10           random_forest_regressor   \n",
       "6      poly_support_vector_regressor   \n",
       "8       rbf_support_vector_regressor   \n",
       "3   polynomial_elastic_net_regressor   \n",
       "2               polynomial_regressor   \n",
       "0                   linear_regressor   \n",
       "5    linear_support_vector_regressor   \n",
       "1              elastic_net_regressor   \n",
       "4      k_nearest_neighbors_regressor   \n",
       "9            decision_tree_regressor   \n",
       "7   sigmoid_support_vector_regressor   \n",
       "\n",
       "                                       BestParameters  BestScore  \n",
       "13  {'regressor__column_transformer__categoricals_...  -0.116407  \n",
       "14  {'regressor__column_transformer__categoricals_...  -0.116407  \n",
       "15  {'regressor__column_transformer__categoricals_...  -0.116407  \n",
       "12  {'regressor__xgb_regressor__reg_lambda': 0.7, ...  -0.117111  \n",
       "11  {'regressor__extra_trees_regressor__random_sta...  -0.125521  \n",
       "10  {'regressor__random_forest_regressor__random_s...  -0.126392  \n",
       "6   {'regressor__poly_support_vector_regressor__sh...  -0.134723  \n",
       "8   {'regressor__rbf_support_vector_regressor__shr...  -0.134943  \n",
       "3   {'regressor__polynomialiser__interaction_only'...  -0.136236  \n",
       "2   {'regressor__polynomialiser__interaction_only'...  -0.142989  \n",
       "0   {'regressor__linear_regressor__normalize': Fal...  -0.147419  \n",
       "5   {'regressor__linear_support_vector_regressor__...  -0.147555  \n",
       "1   {'regressor__elastic_net_regressor__random_sta...  -0.149368  \n",
       "4   {'regressor__k_nearest_neighbors_regressor__p'...  -0.150561  \n",
       "9   {'regressor__decision_tree_regressor__splitter...  -0.154098  \n",
       "7   {'regressor__sigmoid_support_vector_regressor_...  -0.157782  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if regressor_comparison.shape[0] < 14:\n",
    "    regressor = TransformedTargetRegressor(Pipeline([\n",
    "        ('column_transformer', ColumnTransformer([\n",
    "            ('numericals_transformer', 'passthrough', numerical_features),\n",
    "            ('categoricals_transformer', 'passthrough', categorical_features),\n",
    "            ('booleans_transformer', 'passthrough', boolean_features)\n",
    "        ], n_jobs=-1)),\n",
    "        ('xgb_regressor', XGBRegressor())\n",
    "    ]), func=np.log, inverse_func=np.exp)\n",
    "\n",
    "    parameters = {\n",
    "         'n_estimators':      [140],\n",
    "         'max_depth':         [9, 10, 11, 12, 13],\n",
    "         'learning_rate':     [0.050, 0.075, 0.100, 0.125, 0.150],\n",
    "         'min_child_weight':  [1, 2, 3, 5],\n",
    "         'colsample_bytree':  [0.3, 0.4, 0.5, 0.6, 0.7],\n",
    "         'reg_alpha':         [0.4, 0.5, 0.6, 0.7, 0.8],\n",
    "         'reg_lambda':        [0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "         'random_state':      [0],\n",
    "         'n_jobs':            [-1]\n",
    "    }\n",
    "    parameters = {'regressor__xgb_regressor__' + param: parameters[param] for param in parameters.keys()}\n",
    "    parameters.update({\n",
    "        'regressor__column_transformer__categoricals_transformer': [OneHotEncoder(), OrdinalEncoder()]\n",
    "    })\n",
    "\n",
    "    gs = GridSearchCV(estimator=regressor, param_grid=parameters, scoring=scorer, cv=10, verbose=1, n_jobs=-1)\n",
    "    gs.fit(houses_train, y_train)\n",
    "\n",
    "    regressor_comparison = regressor_comparison.append({\n",
    "        'Module':         'xgboost',\n",
    "        'Class':          'XGBRegressor',\n",
    "        'Name':           'xgb_regressor',\n",
    "        'BestParameters': gs.best_params_,\n",
    "        'BestScore':      gs.best_score_\n",
    "    }, ignore_index=True)\n",
    "\n",
    "    regressor_comparison.to_pickle(path='results/regressor_comparison.pickle')\n",
    "    regressor_comparison.to_csv(path_or_buf='results/regressor_comparison.csv', index=False)\n",
    "\n",
    "regressor_comparison.sort_values(by='BestScore', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'regressor__column_transformer__categoricals_transformer': OrdinalEncoder(),\n",
       " 'regressor__xgb_regressor__colsample_bytree': 0.6,\n",
       " 'regressor__xgb_regressor__learning_rate': 0.075,\n",
       " 'regressor__xgb_regressor__max_depth': 13,\n",
       " 'regressor__xgb_regressor__min_child_weight': 3,\n",
       " 'regressor__xgb_regressor__n_estimators': 140,\n",
       " 'regressor__xgb_regressor__n_jobs': -1,\n",
       " 'regressor__xgb_regressor__random_state': 0,\n",
       " 'regressor__xgb_regressor__reg_alpha': 0.4,\n",
       " 'regressor__xgb_regressor__reg_lambda': 0.6}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_comparison.loc[13, 'BestParameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Module</th>\n",
       "      <th>Class</th>\n",
       "      <th>Name</th>\n",
       "      <th>BestParameters</th>\n",
       "      <th>BestScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>xgb_regressor</td>\n",
       "      <td>{'regressor__column_transformer__categoricals_...</td>\n",
       "      <td>-0.116407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>xgb_regressor</td>\n",
       "      <td>{'regressor__column_transformer__categoricals_...</td>\n",
       "      <td>-0.116407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>xgb_regressor</td>\n",
       "      <td>{'regressor__column_transformer__categoricals_...</td>\n",
       "      <td>-0.116407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>xgb_regressor</td>\n",
       "      <td>{'regressor__xgb_regressor__reg_lambda': 0.7, ...</td>\n",
       "      <td>-0.117111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sklearn.ensemble</td>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>extra_trees_regressor</td>\n",
       "      <td>{'regressor__extra_trees_regressor__random_sta...</td>\n",
       "      <td>-0.125521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sklearn.ensemble</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>random_forest_regressor</td>\n",
       "      <td>{'regressor__random_forest_regressor__random_s...</td>\n",
       "      <td>-0.126392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sklearn.svm</td>\n",
       "      <td>SVR</td>\n",
       "      <td>poly_support_vector_regressor</td>\n",
       "      <td>{'regressor__poly_support_vector_regressor__sh...</td>\n",
       "      <td>-0.134723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sklearn.svm</td>\n",
       "      <td>SVR</td>\n",
       "      <td>rbf_support_vector_regressor</td>\n",
       "      <td>{'regressor__rbf_support_vector_regressor__shr...</td>\n",
       "      <td>-0.134943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sklearn.linear_model</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>polynomial_elastic_net_regressor</td>\n",
       "      <td>{'regressor__polynomialiser__interaction_only'...</td>\n",
       "      <td>-0.136236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sklearn.linear_model</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>polynomial_regressor</td>\n",
       "      <td>{'regressor__polynomialiser__interaction_only'...</td>\n",
       "      <td>-0.142989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sklearn.linear_model</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>linear_regressor</td>\n",
       "      <td>{'regressor__linear_regressor__normalize': Fal...</td>\n",
       "      <td>-0.147419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sklearn.svm</td>\n",
       "      <td>SVR</td>\n",
       "      <td>linear_support_vector_regressor</td>\n",
       "      <td>{'regressor__linear_support_vector_regressor__...</td>\n",
       "      <td>-0.147555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sklearn.linear_model</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>elastic_net_regressor</td>\n",
       "      <td>{'regressor__elastic_net_regressor__random_sta...</td>\n",
       "      <td>-0.149368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sklearn.neighbors</td>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>k_nearest_neighbors_regressor</td>\n",
       "      <td>{'regressor__k_nearest_neighbors_regressor__p'...</td>\n",
       "      <td>-0.150561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sklearn.tree</td>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>decision_tree_regressor</td>\n",
       "      <td>{'regressor__decision_tree_regressor__splitter...</td>\n",
       "      <td>-0.154098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sklearn.svm</td>\n",
       "      <td>SVR</td>\n",
       "      <td>sigmoid_support_vector_regressor</td>\n",
       "      <td>{'regressor__sigmoid_support_vector_regressor_...</td>\n",
       "      <td>-0.157782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Module                  Class  \\\n",
       "13               xgboost           XGBRegressor   \n",
       "14               xgboost           XGBRegressor   \n",
       "15               xgboost           XGBRegressor   \n",
       "12               xgboost           XGBRegressor   \n",
       "11      sklearn.ensemble    ExtraTreesRegressor   \n",
       "10      sklearn.ensemble  RandomForestRegressor   \n",
       "6            sklearn.svm                    SVR   \n",
       "8            sklearn.svm                    SVR   \n",
       "3   sklearn.linear_model             ElasticNet   \n",
       "2   sklearn.linear_model       LinearRegression   \n",
       "0   sklearn.linear_model       LinearRegression   \n",
       "5            sklearn.svm                    SVR   \n",
       "1   sklearn.linear_model             ElasticNet   \n",
       "4      sklearn.neighbors    KNeighborsRegressor   \n",
       "9           sklearn.tree  DecisionTreeRegressor   \n",
       "7            sklearn.svm                    SVR   \n",
       "\n",
       "                                Name  \\\n",
       "13                     xgb_regressor   \n",
       "14                     xgb_regressor   \n",
       "15                     xgb_regressor   \n",
       "12                     xgb_regressor   \n",
       "11             extra_trees_regressor   \n",
       "10           random_forest_regressor   \n",
       "6      poly_support_vector_regressor   \n",
       "8       rbf_support_vector_regressor   \n",
       "3   polynomial_elastic_net_regressor   \n",
       "2               polynomial_regressor   \n",
       "0                   linear_regressor   \n",
       "5    linear_support_vector_regressor   \n",
       "1              elastic_net_regressor   \n",
       "4      k_nearest_neighbors_regressor   \n",
       "9            decision_tree_regressor   \n",
       "7   sigmoid_support_vector_regressor   \n",
       "\n",
       "                                       BestParameters  BestScore  \n",
       "13  {'regressor__column_transformer__categoricals_...  -0.116407  \n",
       "14  {'regressor__column_transformer__categoricals_...  -0.116407  \n",
       "15  {'regressor__column_transformer__categoricals_...  -0.116407  \n",
       "12  {'regressor__xgb_regressor__reg_lambda': 0.7, ...  -0.117111  \n",
       "11  {'regressor__extra_trees_regressor__random_sta...  -0.125521  \n",
       "10  {'regressor__random_forest_regressor__random_s...  -0.126392  \n",
       "6   {'regressor__poly_support_vector_regressor__sh...  -0.134723  \n",
       "8   {'regressor__rbf_support_vector_regressor__shr...  -0.134943  \n",
       "3   {'regressor__polynomialiser__interaction_only'...  -0.136236  \n",
       "2   {'regressor__polynomialiser__interaction_only'...  -0.142989  \n",
       "0   {'regressor__linear_regressor__normalize': Fal...  -0.147419  \n",
       "5   {'regressor__linear_support_vector_regressor__...  -0.147555  \n",
       "1   {'regressor__elastic_net_regressor__random_sta...  -0.149368  \n",
       "4   {'regressor__k_nearest_neighbors_regressor__p'...  -0.150561  \n",
       "9   {'regressor__decision_tree_regressor__splitter...  -0.154098  \n",
       "7   {'regressor__sigmoid_support_vector_regressor_...  -0.157782  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if regressor_comparison.shape[0] < 15:\n",
    "    regressor = TransformedTargetRegressor(Pipeline([\n",
    "        ('column_transformer', ColumnTransformer([\n",
    "            ('numericals_transformer', 'passthrough', numerical_features),\n",
    "            ('categoricals_transformer', 'passthrough', categorical_features),\n",
    "            ('booleans_transformer', 'passthrough', boolean_features)\n",
    "        ], n_jobs=-1)),\n",
    "        ('xgb_regressor', XGBRegressor())\n",
    "    ]), func=np.log, inverse_func=np.exp)\n",
    "\n",
    "    parameters = {\n",
    "         'n_estimators':      [140],\n",
    "         'max_depth':         [12, 13, 14, 15],\n",
    "         'learning_rate':     [0.050, 0.075, 0.100],\n",
    "         'min_child_weight':  [2, 3, 4, 5],\n",
    "         'colsample_bytree':  [0.5, 0.6, 0.7],\n",
    "         'reg_alpha':         [0.2, 0.3, 0.4, 0.5],\n",
    "         'reg_lambda':        [0.5, 0.6, 0.7],\n",
    "         'random_state':      [0],\n",
    "         'n_jobs':            [-1]\n",
    "    }\n",
    "    parameters = {'regressor__xgb_regressor__' + param: parameters[param] for param in parameters.keys()}\n",
    "    parameters.update({\n",
    "        'regressor__column_transformer__categoricals_transformer': [OneHotEncoder(), OrdinalEncoder()]\n",
    "    })\n",
    "\n",
    "    gs = GridSearchCV(estimator=regressor, param_grid=parameters, scoring=scorer, cv=10, verbose=1, n_jobs=-1)\n",
    "    gs.fit(houses_train, y_train)\n",
    "\n",
    "    regressor_comparison = regressor_comparison.append({\n",
    "        'Module':         'xgboost',\n",
    "        'Class':          'XGBRegressor',\n",
    "        'Name':           'xgb_regressor',\n",
    "        'BestParameters': gs.best_params_,\n",
    "        'BestScore':      gs.best_score_\n",
    "    }, ignore_index=True)\n",
    "\n",
    "    regressor_comparison.to_pickle(path='results/regressor_comparison.pickle')\n",
    "    regressor_comparison.to_csv(path_or_buf='results/regressor_comparison.csv', index=False)\n",
    "\n",
    "regressor_comparison.sort_values(by='BestScore', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'regressor__column_transformer__categoricals_transformer': OrdinalEncoder(),\n",
       " 'regressor__xgb_regressor__colsample_bytree': 0.6,\n",
       " 'regressor__xgb_regressor__learning_rate': 0.075,\n",
       " 'regressor__xgb_regressor__max_depth': 13,\n",
       " 'regressor__xgb_regressor__min_child_weight': 3,\n",
       " 'regressor__xgb_regressor__n_estimators': 140,\n",
       " 'regressor__xgb_regressor__n_jobs': -1,\n",
       " 'regressor__xgb_regressor__random_state': 0,\n",
       " 'regressor__xgb_regressor__reg_alpha': 0.4,\n",
       " 'regressor__xgb_regressor__reg_lambda': 0.6}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_comparison.loc[14, 'BestParameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Module</th>\n",
       "      <th>Class</th>\n",
       "      <th>Name</th>\n",
       "      <th>BestParameters</th>\n",
       "      <th>BestScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>xgb_regressor</td>\n",
       "      <td>{'regressor__column_transformer__categoricals_...</td>\n",
       "      <td>-0.116407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>xgb_regressor</td>\n",
       "      <td>{'regressor__column_transformer__categoricals_...</td>\n",
       "      <td>-0.116407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>xgb_regressor</td>\n",
       "      <td>{'regressor__column_transformer__categoricals_...</td>\n",
       "      <td>-0.116407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>xgb_regressor</td>\n",
       "      <td>{'regressor__xgb_regressor__reg_lambda': 0.7, ...</td>\n",
       "      <td>-0.117111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sklearn.ensemble</td>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>extra_trees_regressor</td>\n",
       "      <td>{'regressor__extra_trees_regressor__random_sta...</td>\n",
       "      <td>-0.125521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sklearn.ensemble</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>random_forest_regressor</td>\n",
       "      <td>{'regressor__random_forest_regressor__random_s...</td>\n",
       "      <td>-0.126392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sklearn.svm</td>\n",
       "      <td>SVR</td>\n",
       "      <td>poly_support_vector_regressor</td>\n",
       "      <td>{'regressor__poly_support_vector_regressor__sh...</td>\n",
       "      <td>-0.134723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sklearn.svm</td>\n",
       "      <td>SVR</td>\n",
       "      <td>rbf_support_vector_regressor</td>\n",
       "      <td>{'regressor__rbf_support_vector_regressor__shr...</td>\n",
       "      <td>-0.134943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sklearn.linear_model</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>polynomial_elastic_net_regressor</td>\n",
       "      <td>{'regressor__polynomialiser__interaction_only'...</td>\n",
       "      <td>-0.136236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sklearn.linear_model</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>polynomial_regressor</td>\n",
       "      <td>{'regressor__polynomialiser__interaction_only'...</td>\n",
       "      <td>-0.142989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sklearn.linear_model</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>linear_regressor</td>\n",
       "      <td>{'regressor__linear_regressor__normalize': Fal...</td>\n",
       "      <td>-0.147419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sklearn.svm</td>\n",
       "      <td>SVR</td>\n",
       "      <td>linear_support_vector_regressor</td>\n",
       "      <td>{'regressor__linear_support_vector_regressor__...</td>\n",
       "      <td>-0.147555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sklearn.linear_model</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>elastic_net_regressor</td>\n",
       "      <td>{'regressor__elastic_net_regressor__random_sta...</td>\n",
       "      <td>-0.149368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sklearn.neighbors</td>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>k_nearest_neighbors_regressor</td>\n",
       "      <td>{'regressor__k_nearest_neighbors_regressor__p'...</td>\n",
       "      <td>-0.150561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sklearn.tree</td>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>decision_tree_regressor</td>\n",
       "      <td>{'regressor__decision_tree_regressor__splitter...</td>\n",
       "      <td>-0.154098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sklearn.svm</td>\n",
       "      <td>SVR</td>\n",
       "      <td>sigmoid_support_vector_regressor</td>\n",
       "      <td>{'regressor__sigmoid_support_vector_regressor_...</td>\n",
       "      <td>-0.157782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Module                  Class  \\\n",
       "13               xgboost           XGBRegressor   \n",
       "14               xgboost           XGBRegressor   \n",
       "15               xgboost           XGBRegressor   \n",
       "12               xgboost           XGBRegressor   \n",
       "11      sklearn.ensemble    ExtraTreesRegressor   \n",
       "10      sklearn.ensemble  RandomForestRegressor   \n",
       "6            sklearn.svm                    SVR   \n",
       "8            sklearn.svm                    SVR   \n",
       "3   sklearn.linear_model             ElasticNet   \n",
       "2   sklearn.linear_model       LinearRegression   \n",
       "0   sklearn.linear_model       LinearRegression   \n",
       "5            sklearn.svm                    SVR   \n",
       "1   sklearn.linear_model             ElasticNet   \n",
       "4      sklearn.neighbors    KNeighborsRegressor   \n",
       "9           sklearn.tree  DecisionTreeRegressor   \n",
       "7            sklearn.svm                    SVR   \n",
       "\n",
       "                                Name  \\\n",
       "13                     xgb_regressor   \n",
       "14                     xgb_regressor   \n",
       "15                     xgb_regressor   \n",
       "12                     xgb_regressor   \n",
       "11             extra_trees_regressor   \n",
       "10           random_forest_regressor   \n",
       "6      poly_support_vector_regressor   \n",
       "8       rbf_support_vector_regressor   \n",
       "3   polynomial_elastic_net_regressor   \n",
       "2               polynomial_regressor   \n",
       "0                   linear_regressor   \n",
       "5    linear_support_vector_regressor   \n",
       "1              elastic_net_regressor   \n",
       "4      k_nearest_neighbors_regressor   \n",
       "9            decision_tree_regressor   \n",
       "7   sigmoid_support_vector_regressor   \n",
       "\n",
       "                                       BestParameters  BestScore  \n",
       "13  {'regressor__column_transformer__categoricals_...  -0.116407  \n",
       "14  {'regressor__column_transformer__categoricals_...  -0.116407  \n",
       "15  {'regressor__column_transformer__categoricals_...  -0.116407  \n",
       "12  {'regressor__xgb_regressor__reg_lambda': 0.7, ...  -0.117111  \n",
       "11  {'regressor__extra_trees_regressor__random_sta...  -0.125521  \n",
       "10  {'regressor__random_forest_regressor__random_s...  -0.126392  \n",
       "6   {'regressor__poly_support_vector_regressor__sh...  -0.134723  \n",
       "8   {'regressor__rbf_support_vector_regressor__shr...  -0.134943  \n",
       "3   {'regressor__polynomialiser__interaction_only'...  -0.136236  \n",
       "2   {'regressor__polynomialiser__interaction_only'...  -0.142989  \n",
       "0   {'regressor__linear_regressor__normalize': Fal...  -0.147419  \n",
       "5   {'regressor__linear_support_vector_regressor__...  -0.147555  \n",
       "1   {'regressor__elastic_net_regressor__random_sta...  -0.149368  \n",
       "4   {'regressor__k_nearest_neighbors_regressor__p'...  -0.150561  \n",
       "9   {'regressor__decision_tree_regressor__splitter...  -0.154098  \n",
       "7   {'regressor__sigmoid_support_vector_regressor_...  -0.157782  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if regressor_comparison.shape[0] < 16:\n",
    "    regressor = TransformedTargetRegressor(Pipeline([\n",
    "        ('column_transformer', ColumnTransformer([\n",
    "            ('numericals_transformer', 'passthrough', numerical_features),\n",
    "            ('categoricals_transformer', 'passthrough', categorical_features),\n",
    "            ('booleans_transformer', 'passthrough', boolean_features)\n",
    "        ], n_jobs=-1)),\n",
    "        ('xgb_regressor', XGBRegressor())\n",
    "    ]), func=np.log, inverse_func=np.exp)\n",
    "\n",
    "    parameters = {\n",
    "         'n_estimators':      [100, 120, 140, 160, 180, 200, 250, 300, 350],\n",
    "         'max_depth':         [13],\n",
    "         'learning_rate':     [0.075],\n",
    "         'min_child_weight':  [3],\n",
    "         'colsample_bytree':  [0.6],\n",
    "         'reg_alpha':         [0.4],\n",
    "         'reg_lambda':        [0.6],\n",
    "         'random_state':      [0],\n",
    "         'n_jobs':            [-1]\n",
    "    }\n",
    "    parameters = {'regressor__xgb_regressor__' + param: parameters[param] for param in parameters.keys()}\n",
    "    parameters.update({\n",
    "        'regressor__column_transformer__categoricals_transformer': [OrdinalEncoder()]\n",
    "    })\n",
    "\n",
    "    gs = GridSearchCV(estimator=regressor, param_grid=parameters, scoring=scorer, cv=10, verbose=1, n_jobs=-1)\n",
    "    gs.fit(houses_train, y_train)\n",
    "\n",
    "    regressor_comparison = regressor_comparison.append({\n",
    "        'Module':         'xgboost',\n",
    "        'Class':          'XGBRegressor',\n",
    "        'Name':           'xgb_regressor',\n",
    "        'BestParameters': gs.best_params_,\n",
    "        'BestScore':      gs.best_score_\n",
    "    }, ignore_index=True)\n",
    "\n",
    "    regressor_comparison.to_pickle(path='results/regressor_comparison.pickle')\n",
    "    regressor_comparison.to_csv(path_or_buf='results/regressor_comparison.csv', index=False)\n",
    "\n",
    "regressor_comparison.sort_values(by='BestScore', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best performing regression model found is an XGBRegressor with the following parameters. On average, the regressor achieves a mean absolute percentage error of 11.6% on the validation sets of a 10-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'regressor__column_transformer__categoricals_transformer': OrdinalEncoder(),\n",
       " 'regressor__xgb_regressor__colsample_bytree': 0.6,\n",
       " 'regressor__xgb_regressor__learning_rate': 0.075,\n",
       " 'regressor__xgb_regressor__max_depth': 13,\n",
       " 'regressor__xgb_regressor__min_child_weight': 3,\n",
       " 'regressor__xgb_regressor__n_estimators': 140,\n",
       " 'regressor__xgb_regressor__n_jobs': -1,\n",
       " 'regressor__xgb_regressor__random_state': 0,\n",
       " 'regressor__xgb_regressor__reg_alpha': 0.4,\n",
       " 'regressor__xgb_regressor__reg_lambda': 0.6}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_comparison.loc[15, 'BestParameters']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting ensemble\n",
    "\n",
    "We study the results of a voting regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_estimator(idx):\n",
    "    (module_name, class_name, regressor_name, parameters, _) = list(regressor_comparison.loc[idx])\n",
    "    \n",
    "    module_of_regressor = import_module(module_name)\n",
    "    class_of_regressor = getattr(module_of_regressor, class_name)\n",
    "    regressor = TransformedTargetRegressor(Pipeline([\n",
    "        ('column_transformer', ColumnTransformer([\n",
    "            ('numericals_transformer', Pipeline([\n",
    "                ('scaler', 'passthrough'),\n",
    "                ('pca', 'passthrough')\n",
    "            ]), numerical_features),\n",
    "            ('categoricals_transformer', OneHotEncoder(), categorical_features),\n",
    "            ('booleans_transformer', 'passthrough', boolean_features)\n",
    "        ], n_jobs=-1)),\n",
    "        ('polynomialiser', 'passthrough'),\n",
    "        (regressor_name, class_of_regressor())\n",
    "    ]), func=np.log, inverse_func=np.exp)\n",
    "    regressor.set_params(**parameters)\n",
    "    \n",
    "    return regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean valid score: 0.128\n"
     ]
    }
   ],
   "source": [
    "voting_regressor = VotingRegressor([('reg_{}'.format(idx), load_estimator(idx))\n",
    "                                    for idx in list(range(12)) + [13]], n_jobs=-1)\n",
    "\n",
    "cv_results = cross_validate(voting_regressor, houses_train, y_train, scoring=scorer, cv=10, n_jobs=-1)\n",
    "print('Mean valid score: {:.3f}'.format(-cv_results['test_score'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The voting regressor does not seem to achieve better results.\n",
    "\n",
    "## Feature selection\n",
    "\n",
    "We use the feature importances of our best performing single regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_regressor = load_estimator(13)\n",
    "\n",
    "cv_results = cross_validate(xgb_regressor, houses_train, y_train, scoring=scorer, cv=10, return_estimator=True,\n",
    "                            n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate([\n",
    "    numerical_features,\n",
    "    categorical_features,\n",
    "#    cv_results['estimator'][0].regressor_['column_transformer'].transformers_[1][1]\\\n",
    "#        .get_feature_names(categorical_features),\n",
    "    boolean_features\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sqft_living log</th>\n",
       "      <th>base_area log</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>bedrooms bin</th>\n",
       "      <th>bathrooms bin</th>\n",
       "      <th>bathrooms_ratio bin</th>\n",
       "      <th>floors bin</th>\n",
       "      <th>yr_built bin</th>\n",
       "      <th>zipcode cat</th>\n",
       "      <th>condition bin</th>\n",
       "      <th>grade bin</th>\n",
       "      <th>view bin</th>\n",
       "      <th>has_basement</th>\n",
       "      <th>is_renovated</th>\n",
       "      <th>waterfront</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.079319</td>\n",
       "      <td>0.003343</td>\n",
       "      <td>0.004262</td>\n",
       "      <td>0.019970</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>0.011281</td>\n",
       "      <td>0.443228</td>\n",
       "      <td>0.013450</td>\n",
       "      <td>0.097627</td>\n",
       "      <td>0.084581</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>0.007777</td>\n",
       "      <td>0.183281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.083867</td>\n",
       "      <td>0.003422</td>\n",
       "      <td>0.004430</td>\n",
       "      <td>0.019683</td>\n",
       "      <td>0.005127</td>\n",
       "      <td>0.002639</td>\n",
       "      <td>0.029500</td>\n",
       "      <td>0.002629</td>\n",
       "      <td>0.004543</td>\n",
       "      <td>0.009863</td>\n",
       "      <td>0.449871</td>\n",
       "      <td>0.012580</td>\n",
       "      <td>0.098354</td>\n",
       "      <td>0.095561</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.006319</td>\n",
       "      <td>0.169141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.084354</td>\n",
       "      <td>0.003319</td>\n",
       "      <td>0.004695</td>\n",
       "      <td>0.021386</td>\n",
       "      <td>0.005320</td>\n",
       "      <td>0.002531</td>\n",
       "      <td>0.028014</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>0.010379</td>\n",
       "      <td>0.472341</td>\n",
       "      <td>0.013346</td>\n",
       "      <td>0.101238</td>\n",
       "      <td>0.097240</td>\n",
       "      <td>0.002787</td>\n",
       "      <td>0.006692</td>\n",
       "      <td>0.140433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.082373</td>\n",
       "      <td>0.003305</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>0.022488</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.027551</td>\n",
       "      <td>0.002559</td>\n",
       "      <td>0.003888</td>\n",
       "      <td>0.009343</td>\n",
       "      <td>0.468264</td>\n",
       "      <td>0.013322</td>\n",
       "      <td>0.099493</td>\n",
       "      <td>0.081991</td>\n",
       "      <td>0.002711</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.162684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.086395</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>0.004489</td>\n",
       "      <td>0.019989</td>\n",
       "      <td>0.005369</td>\n",
       "      <td>0.002719</td>\n",
       "      <td>0.022020</td>\n",
       "      <td>0.002408</td>\n",
       "      <td>0.004250</td>\n",
       "      <td>0.009657</td>\n",
       "      <td>0.465733</td>\n",
       "      <td>0.014959</td>\n",
       "      <td>0.105743</td>\n",
       "      <td>0.095688</td>\n",
       "      <td>0.002855</td>\n",
       "      <td>0.005990</td>\n",
       "      <td>0.148659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.081845</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>0.004752</td>\n",
       "      <td>0.021012</td>\n",
       "      <td>0.005341</td>\n",
       "      <td>0.002447</td>\n",
       "      <td>0.033922</td>\n",
       "      <td>0.002438</td>\n",
       "      <td>0.005478</td>\n",
       "      <td>0.009983</td>\n",
       "      <td>0.466111</td>\n",
       "      <td>0.016220</td>\n",
       "      <td>0.096997</td>\n",
       "      <td>0.108142</td>\n",
       "      <td>0.002780</td>\n",
       "      <td>0.007804</td>\n",
       "      <td>0.131387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.083393</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>0.004320</td>\n",
       "      <td>0.021753</td>\n",
       "      <td>0.005436</td>\n",
       "      <td>0.002292</td>\n",
       "      <td>0.022879</td>\n",
       "      <td>0.002575</td>\n",
       "      <td>0.007257</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>0.494026</td>\n",
       "      <td>0.014462</td>\n",
       "      <td>0.095329</td>\n",
       "      <td>0.071340</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>0.007012</td>\n",
       "      <td>0.151759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.082255</td>\n",
       "      <td>0.003683</td>\n",
       "      <td>0.004686</td>\n",
       "      <td>0.020151</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>0.020908</td>\n",
       "      <td>0.002636</td>\n",
       "      <td>0.008085</td>\n",
       "      <td>0.009871</td>\n",
       "      <td>0.469738</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.097801</td>\n",
       "      <td>0.101826</td>\n",
       "      <td>0.002776</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>0.146046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.085387</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.004730</td>\n",
       "      <td>0.021167</td>\n",
       "      <td>0.005550</td>\n",
       "      <td>0.003002</td>\n",
       "      <td>0.024005</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>0.004484</td>\n",
       "      <td>0.009135</td>\n",
       "      <td>0.486358</td>\n",
       "      <td>0.012225</td>\n",
       "      <td>0.098277</td>\n",
       "      <td>0.095429</td>\n",
       "      <td>0.003131</td>\n",
       "      <td>0.007448</td>\n",
       "      <td>0.133775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.087627</td>\n",
       "      <td>0.003821</td>\n",
       "      <td>0.004652</td>\n",
       "      <td>0.020765</td>\n",
       "      <td>0.005384</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.023174</td>\n",
       "      <td>0.002471</td>\n",
       "      <td>0.006591</td>\n",
       "      <td>0.009774</td>\n",
       "      <td>0.474780</td>\n",
       "      <td>0.015860</td>\n",
       "      <td>0.093140</td>\n",
       "      <td>0.095514</td>\n",
       "      <td>0.002684</td>\n",
       "      <td>0.008057</td>\n",
       "      <td>0.143116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sqft_living log  base_area log  sqft_lot       lat      long  bedrooms bin  \\\n",
       "0         0.079319       0.003343  0.004262  0.019970  0.004975      0.002299   \n",
       "1         0.083867       0.003422  0.004430  0.019683  0.005127      0.002639   \n",
       "2         0.084354       0.003319  0.004695  0.021386  0.005320      0.002531   \n",
       "3         0.082373       0.003305  0.004635  0.022488  0.005495      0.002419   \n",
       "4         0.086395       0.003077  0.004489  0.019989  0.005369      0.002719   \n",
       "5         0.081845       0.003341  0.004752  0.021012  0.005341      0.002447   \n",
       "6         0.083393       0.003490  0.004320  0.021753  0.005436      0.002292   \n",
       "7         0.082255       0.003683  0.004686  0.020151  0.005373      0.002375   \n",
       "8         0.085387       0.003538  0.004730  0.021167  0.005550      0.003002   \n",
       "9         0.087627       0.003821  0.004652  0.020765  0.005384      0.002591   \n",
       "\n",
       "   bathrooms bin  bathrooms_ratio bin  floors bin  yr_built bin  zipcode cat  \\\n",
       "0       0.035100             0.002077    0.004906      0.011281     0.443228   \n",
       "1       0.029500             0.002629    0.004543      0.009863     0.449871   \n",
       "2       0.028014             0.002494    0.003432      0.010379     0.472341   \n",
       "3       0.027551             0.002559    0.003888      0.009343     0.468264   \n",
       "4       0.022020             0.002408    0.004250      0.009657     0.465733   \n",
       "5       0.033922             0.002438    0.005478      0.009983     0.466111   \n",
       "6       0.022879             0.002575    0.007257      0.009781     0.494026   \n",
       "7       0.020908             0.002636    0.008085      0.009871     0.469738   \n",
       "8       0.024005             0.002359    0.004484      0.009135     0.486358   \n",
       "9       0.023174             0.002471    0.006591      0.009774     0.474780   \n",
       "\n",
       "   condition bin  grade bin  view bin  has_basement  is_renovated  waterfront  \n",
       "0       0.013450   0.097627  0.084581      0.002524      0.007777    0.183281  \n",
       "1       0.012580   0.098354  0.095561      0.002472      0.006319    0.169141  \n",
       "2       0.013346   0.101238  0.097240      0.002787      0.006692    0.140433  \n",
       "3       0.013322   0.099493  0.081991      0.002711      0.007480    0.162684  \n",
       "4       0.014959   0.105743  0.095688      0.002855      0.005990    0.148659  \n",
       "5       0.016220   0.096997  0.108142      0.002780      0.007804    0.131387  \n",
       "6       0.014462   0.095329  0.071340      0.002897      0.007012    0.151759  \n",
       "7       0.014006   0.097801  0.101826      0.002776      0.007784    0.146046  \n",
       "8       0.012225   0.098277  0.095429      0.003131      0.007448    0.133775  \n",
       "9       0.015860   0.093140  0.095514      0.002684      0.008057    0.143116  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(columns=features)\n",
    "\n",
    "for regressor in cv_results['estimator']:\n",
    "    feature_importances = feature_importances\\\n",
    "                          .append(dict(zip(features, regressor.regressor_['xgb_regressor'].feature_importances_)),\n",
    "                                  ignore_index=True)\n",
    "    \n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>mean importance</th>\n",
       "      <th>cumsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>zipcode cat</td>\n",
       "      <td>0.469045</td>\n",
       "      <td>0.469045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>waterfront</td>\n",
       "      <td>0.151028</td>\n",
       "      <td>0.620073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>grade bin</td>\n",
       "      <td>0.098400</td>\n",
       "      <td>0.718473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>view bin</td>\n",
       "      <td>0.092731</td>\n",
       "      <td>0.811204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sqft_living log</td>\n",
       "      <td>0.083681</td>\n",
       "      <td>0.894885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bathrooms bin</td>\n",
       "      <td>0.026707</td>\n",
       "      <td>0.921592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lat</td>\n",
       "      <td>0.020836</td>\n",
       "      <td>0.942429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>condition bin</td>\n",
       "      <td>0.014043</td>\n",
       "      <td>0.956472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>yr_built bin</td>\n",
       "      <td>0.009907</td>\n",
       "      <td>0.966379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>is_renovated</td>\n",
       "      <td>0.007236</td>\n",
       "      <td>0.973615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>long</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.978952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>floors bin</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.984243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sqft_lot</td>\n",
       "      <td>0.004565</td>\n",
       "      <td>0.988808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>base_area log</td>\n",
       "      <td>0.003434</td>\n",
       "      <td>0.992242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>has_basement</td>\n",
       "      <td>0.002762</td>\n",
       "      <td>0.995004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bedrooms bin</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.997535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bathrooms_ratio bin</td>\n",
       "      <td>0.002465</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                feature  mean importance    cumsum\n",
       "10          zipcode cat         0.469045  0.469045\n",
       "16           waterfront         0.151028  0.620073\n",
       "12            grade bin         0.098400  0.718473\n",
       "13             view bin         0.092731  0.811204\n",
       "0       sqft_living log         0.083681  0.894885\n",
       "6         bathrooms bin         0.026707  0.921592\n",
       "3                   lat         0.020836  0.942429\n",
       "11        condition bin         0.014043  0.956472\n",
       "9          yr_built bin         0.009907  0.966379\n",
       "15         is_renovated         0.007236  0.973615\n",
       "4                  long         0.005337  0.978952\n",
       "8            floors bin         0.005291  0.984243\n",
       "2              sqft_lot         0.004565  0.988808\n",
       "1         base_area log         0.003434  0.992242\n",
       "14         has_basement         0.002762  0.995004\n",
       "5          bedrooms bin         0.002532  0.997535\n",
       "7   bathrooms_ratio bin         0.002465  1.000000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_feature_importances = feature_importances.mean().reset_index()\n",
    "mean_feature_importances.columns = ['feature', 'mean importance']\n",
    "mean_feature_importances['cumsum'] = mean_feature_importances['mean importance'].sort_values(ascending=False)\\\n",
    "                                    .cumsum()\n",
    "\n",
    "mean_feature_importances.sort_values('mean importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = mean_feature_importances.sort_values('mean importance', ascending=False).index\n",
    "scores = []\n",
    "\n",
    "for idx in range(1, indices.size + 1):\n",
    "    regressor = TransformedTargetRegressor(make_pipeline(\n",
    "        xgb_regressor.regressor['column_transformer'],\n",
    "        ColumnTransformer([('selector', 'passthrough', indices[:idx])]),\n",
    "        xgb_regressor.regressor['xgb_regressor']\n",
    "    ), func=np.log, inverse_func=np.exp)\n",
    "\n",
    "    cv_results = cross_validate(regressor, houses_train, y_train, scoring=scorer, cv=10, n_jobs=-1)\n",
    "    scores.append(-cv_results['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 6000x1500 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 5), dpi=300)\n",
    "plt.plot(range(1, indices.size + 1), scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(scores) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum is achieved at 13 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of regressor\n",
    "\n",
    "We train our regressor with the top 13 features on the whole train set and evaluate its quality on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = TransformedTargetRegressor(make_pipeline(\n",
    "    xgb_regressor.regressor['column_transformer'],\n",
    "    ColumnTransformer([('selector', 'passthrough', indices[:np.argmin(scores) + 1])]),\n",
    "    xgb_regressor.regressor['xgb_regressor']\n",
    "), func=np.log, inverse_func=np.exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_test = pd.read_pickle('data/king_county_test.pickle')\n",
    "\n",
    "preprocessor_clean = joblib.load('objects/preprocessor_clean.joblib')\n",
    "preprocessor_engineer = joblib.load('objects/preprocessor_engineer.joblib')\n",
    "preprocessor = make_pipeline(preprocessor_clean, preprocessor_engineer)\n",
    "\n",
    "houses_test = preprocessor.transform(houses_test)\n",
    "y_test = houses_test['price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2:   0.972, 0.886\n",
      "RMSE:  61408, 124520\n",
      "MAE:   37346, 64371\n",
      "MedAE: 23668, 37380\n",
      "MAPE:  0.071, 0.118\n"
     ]
    }
   ],
   "source": [
    "regressor.fit(houses_train, y_train)\n",
    "print_evaluation(regressor, houses_train, houses_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the test set, the mean absolute percentage error is about 11.8% and the median absolute error is about $ 37,400."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "456px",
    "width": "716px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "217px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
